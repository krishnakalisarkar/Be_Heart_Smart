{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcde4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data to a dataframe\n",
    "\n",
    "cardio_df = pd.read_csv(\"cardio_data_cleaned.csv\")\n",
    "  \n",
    "cardio_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460335ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate our target(output) and features (input)\n",
    "\n",
    "#Target variable\n",
    "y = cardio_df[\"cardio\"]\n",
    "\n",
    "#Feature variables\n",
    "X = cardio_df.drop(columns=\"cardio\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ed74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5955b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa32a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training, validation and testing sets. The ratio 80:10:10.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size = 0.8\n",
    "\n",
    "# First, split the dataset into training and remaining datasets\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n",
    "\n",
    "# The validation dataset and test dataset are each 10%. So, each equal to the 50% of the remaining dataset\n",
    "\n",
    "test_size = 0.5\n",
    "valid_size= 0.5\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "print(X_train.shape), print(y_train.shape)\n",
    "print(X_valid.shape), print(y_valid.shape)\n",
    "print(X_test.shape), print(y_test.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f29d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fitting Standard Scaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049f047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the training data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b9a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our logistic regression model\n",
    "\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25b1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the validation data\n",
    "X_valid_scaled = X_scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf51c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model using the validation data\n",
    "y_pred = model.predict(X_valid_scaled)\n",
    "predictions = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_valid}).reset_index(drop=True)\n",
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "matrix = confusion_matrix(y_valid, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8394f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_valid, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f7e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Forest classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7832615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our Random forest model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eccf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the RF model\n",
    "y_pred = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8e441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the predicted values into a dataframe\n",
    "predictions = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27fd1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1846ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn import preprocessing\n",
    ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.4, random_state=0)\n",
    ">>> scaler = preprocessing.StandardScaler().fit(X_train)\n",
    ">>> X_train_transformed = scaler.transform(X_train)\n",
    ">>> clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
    ">>> X_test_transformed = scaler.transform(X_test)\n",
    ">>> clf.score(X_test_transformed, y_test)\n",
    "0.93    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.model_selection import cross_val_score\n",
    ">>> clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    ">>> scores = cross_val_score(clf, X, y, cv=5)\n",
    ">>> scores\n",
    "array([0.96..., 1. , 0.96..., 0.96..., 1. ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801082ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5461a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
