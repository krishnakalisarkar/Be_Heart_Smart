{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad64256c",
   "metadata": {},
   "source": [
    "## Deep learning on Be heart Smart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f3eb648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96ac9448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86650</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26503</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59853</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24167</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>170.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31439</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>146.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Age  gender  height  weight  systolic_bp  diastolic_bp  cholesterol  \\\n",
       "0  86650   51       1   171.0    29.0        110.0          70.0            2   \n",
       "1  26503   49       1   160.0    30.0        120.0          80.0            1   \n",
       "2  59853   58       1   143.0    30.0        103.0          61.0            2   \n",
       "3  24167   47       2   170.0    31.0        150.0          90.0            2   \n",
       "4  31439   42       1   146.0    32.0        100.0          70.0            1   \n",
       "\n",
       "   glucose  smoker  alcohol_intake  active  cardio_disease  \n",
       "0        1       0               0       1               1  \n",
       "1        1       0               0       1               1  \n",
       "2        1       0               0       1               0  \n",
       "3        2       0               0       1               1  \n",
       "4        1       0               0       0               0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the cardio data to a dataframe\n",
    "path = ('../Resources/cardio_cleaned.csv')\n",
    "cardio_df = pd.read_csv(path)  \n",
    "cardio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f54ab415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86650</td>\n",
       "      <td>9.9</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26503</td>\n",
       "      <td>11.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59853</td>\n",
       "      <td>14.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24167</td>\n",
       "      <td>10.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31439</td>\n",
       "      <td>15.0</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   BMI weight_status obesity_status\n",
       "0  86650   9.9   underweight             no\n",
       "1  26503  11.7   underweight             no\n",
       "2  59853  14.7   underweight             no\n",
       "3  24167  10.7   underweight             no\n",
       "4  31439  15.0   underweight             no"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the BMI data to a dataframe\n",
    "path = ('../Resources/BMI.csv')\n",
    "BMI_df = pd.read_csv(path)  \n",
    "BMI_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8299cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86650</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26503</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59853</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24167</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>170.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31439</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>146.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Age  gender  height  weight  systolic_bp  diastolic_bp  cholesterol  \\\n",
       "0  86650   51       1   171.0    29.0        110.0          70.0            2   \n",
       "1  26503   49       1   160.0    30.0        120.0          80.0            1   \n",
       "2  59853   58       1   143.0    30.0        103.0          61.0            2   \n",
       "3  24167   47       2   170.0    31.0        150.0          90.0            2   \n",
       "4  31439   42       1   146.0    32.0        100.0          70.0            1   \n",
       "\n",
       "   glucose  smoker  alcohol_intake  active  cardio_disease   BMI  \\\n",
       "0        1       0               0       1               1   9.9   \n",
       "1        1       0               0       1               1  11.7   \n",
       "2        1       0               0       1               0  14.7   \n",
       "3        2       0               0       1               1  10.7   \n",
       "4        1       0               0       0               0  15.0   \n",
       "\n",
       "  weight_status obesity_status  \n",
       "0   underweight             no  \n",
       "1   underweight             no  \n",
       "2   underweight             no  \n",
       "3   underweight             no  \n",
       "4   underweight             no  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two DataFrames on id.\n",
    "cardio_complete_df = pd.merge(cardio_df, BMI_df, on=\"id\")\n",
    "cardio_complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8c71f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68297, 16)\n",
      "id                  int64\n",
      "Age                 int64\n",
      "gender              int64\n",
      "height            float64\n",
      "weight            float64\n",
      "systolic_bp       float64\n",
      "diastolic_bp      float64\n",
      "cholesterol         int64\n",
      "glucose             int64\n",
      "smoker              int64\n",
      "alcohol_intake      int64\n",
      "active              int64\n",
      "cardio_disease      int64\n",
      "BMI               float64\n",
      "weight_status      object\n",
      "obesity_status     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(cardio_complete_df.shape)\n",
    "print(cardio_complete_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7a04122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86650</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26503</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59853</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24167</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>170.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31439</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>146.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Age  gender  height  weight   BMI weight_status obesity_status  \\\n",
       "0  86650   51       1   171.0    29.0   9.9   underweight             no   \n",
       "1  26503   49       1   160.0    30.0  11.7   underweight             no   \n",
       "2  59853   58       1   143.0    30.0  14.7   underweight             no   \n",
       "3  24167   47       2   170.0    31.0  10.7   underweight             no   \n",
       "4  31439   42       1   146.0    32.0  15.0   underweight             no   \n",
       "\n",
       "   systolic_bp  diastolic_bp  cholesterol  glucose  smoker  alcohol_intake  \\\n",
       "0        110.0          70.0            2        1       0               0   \n",
       "1        120.0          80.0            1        1       0               0   \n",
       "2        103.0          61.0            2        1       0               0   \n",
       "3        150.0          90.0            2        2       0               0   \n",
       "4        100.0          70.0            1        1       0               0   \n",
       "\n",
       "   active  cardio_disease  \n",
       "0       1               1  \n",
       "1       1               1  \n",
       "2       1               0  \n",
       "3       1               1  \n",
       "4       0               0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-aarange columns in the merged DataFrame\n",
    "rearranged_columns = [\"id\", \"Age\", \"gender\", \"height\", \"weight\", \"BMI\", \"weight_status\", \"obesity_status\", \n",
    "                       \"systolic_bp\", \"diastolic_bp\", \"cholesterol\", \"glucose\", \"smoker\", \"alcohol_intake\", \n",
    "                       \"active\", \"cardio_disease\"]\n",
    "cardio_complete_df = cardio_complete_df[rearranged_columns]\n",
    "cardio_complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3a32cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49972.437969</td>\n",
       "      <td>52.819304</td>\n",
       "      <td>1.348375</td>\n",
       "      <td>164.452070</td>\n",
       "      <td>74.072282</td>\n",
       "      <td>27.420065</td>\n",
       "      <td>126.351538</td>\n",
       "      <td>81.215983</td>\n",
       "      <td>1.363383</td>\n",
       "      <td>1.225134</td>\n",
       "      <td>0.087778</td>\n",
       "      <td>0.053165</td>\n",
       "      <td>0.803549</td>\n",
       "      <td>0.493272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28851.286589</td>\n",
       "      <td>6.771405</td>\n",
       "      <td>0.476459</td>\n",
       "      <td>7.820924</td>\n",
       "      <td>14.254568</td>\n",
       "      <td>5.184147</td>\n",
       "      <td>16.067301</td>\n",
       "      <td>9.262086</td>\n",
       "      <td>0.678032</td>\n",
       "      <td>0.571167</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>0.224364</td>\n",
       "      <td>0.397316</td>\n",
       "      <td>0.499958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24994.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50017.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>26.300000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74868.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99999.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>85.800000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           Age        gender        height        weight  \\\n",
       "count  68297.000000  68297.000000  68297.000000  68297.000000  68297.000000   \n",
       "mean   49972.437969     52.819304      1.348375    164.452070     74.072282   \n",
       "std    28851.286589      6.771405      0.476459      7.820924     14.254568   \n",
       "min        0.000000     29.000000      1.000000    135.000000     29.000000   \n",
       "25%    24994.000000     48.000000      1.000000    159.000000     65.000000   \n",
       "50%    50017.000000     53.000000      1.000000    165.000000     72.000000   \n",
       "75%    74868.000000     58.000000      2.000000    170.000000     82.000000   \n",
       "max    99999.000000     64.000000      2.000000    207.000000    200.000000   \n",
       "\n",
       "                BMI   systolic_bp  diastolic_bp   cholesterol       glucose  \\\n",
       "count  68297.000000  68297.000000  68297.000000  68297.000000  68297.000000   \n",
       "mean      27.420065    126.351538     81.215983      1.363383      1.225134   \n",
       "std        5.184147     16.067301      9.262086      0.678032      0.571167   \n",
       "min        9.900000     80.000000     40.000000      1.000000      1.000000   \n",
       "25%       23.900000    120.000000     80.000000      1.000000      1.000000   \n",
       "50%       26.300000    120.000000     80.000000      1.000000      1.000000   \n",
       "75%       30.100000    140.000000     90.000000      1.000000      1.000000   \n",
       "max       85.800000    180.000000    120.000000      3.000000      3.000000   \n",
       "\n",
       "             smoker  alcohol_intake        active  cardio_disease  \n",
       "count  68297.000000    68297.000000  68297.000000    68297.000000  \n",
       "mean       0.087778        0.053165      0.803549        0.493272  \n",
       "std        0.282974        0.224364      0.397316        0.499958  \n",
       "min        0.000000        0.000000      0.000000        0.000000  \n",
       "25%        0.000000        0.000000      1.000000        0.000000  \n",
       "50%        0.000000        0.000000      1.000000        0.000000  \n",
       "75%        0.000000        0.000000      1.000000        1.000000  \n",
       "max        1.000000        1.000000      1.000000        1.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio_complete_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "573931ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the continuous variables weight_status, and obesity_status from string to numeric.\n",
    "# Defining a function string_to_numeric.\n",
    "def string_to_numeric(variable):\n",
    "    if variable == \"underweight\":\n",
    "        return 1\n",
    "    elif variable == \"normal\":\n",
    "        return 2\n",
    "    elif variable == \"overweight\":\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca3fa4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function string_to_numeric on column weight_status \n",
    "cardio_complete_df[\"weight_status\"] = cardio_complete_df[\"weight_status\"].apply(string_to_numeric)\n",
    "cardio_complete_df.head()\n",
    "\n",
    "# Change the obesity_status to numeric\n",
    "cardio_complete_df[\"obesity_status\"] = cardio_complete_df[\"obesity_status\"].apply(lambda x: 1 if x == \"yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fabd8a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86650</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26503</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59853</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24167</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>170.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31439</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>146.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50443</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>146.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54851</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>154.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68667</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21040</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>47872</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>153.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Age  gender  height  weight   BMI  weight_status  obesity_status  \\\n",
       "0  86650   51       1   171.0    29.0   9.9              1               0   \n",
       "1  26503   49       1   160.0    30.0  11.7              1               0   \n",
       "2  59853   58       1   143.0    30.0  14.7              1               0   \n",
       "3  24167   47       2   170.0    31.0  10.7              1               0   \n",
       "4  31439   42       1   146.0    32.0  15.0              1               0   \n",
       "5  50443   54       1   146.0    32.0  15.0              1               0   \n",
       "6  54851   59       1   154.0    32.0  13.5              1               0   \n",
       "7  68667   52       1   143.0    33.0  16.1              1               0   \n",
       "8  21040   62       1   143.0    34.0  16.6              1               0   \n",
       "9  47872   57       1   153.0    34.0  14.5              1               0   \n",
       "\n",
       "   systolic_bp  diastolic_bp  cholesterol  glucose  smoker  alcohol_intake  \\\n",
       "0        110.0          70.0            2        1       0               0   \n",
       "1        120.0          80.0            1        1       0               0   \n",
       "2        103.0          61.0            2        1       0               0   \n",
       "3        150.0          90.0            2        2       0               0   \n",
       "4        100.0          70.0            1        1       0               0   \n",
       "5        130.0          80.0            1        2       0               0   \n",
       "6        110.0          60.0            1        1       0               0   \n",
       "7        100.0          60.0            1        1       0               0   \n",
       "8        100.0          70.0            1        1       0               0   \n",
       "9        110.0          70.0            3        3       0               0   \n",
       "\n",
       "   active  cardio_disease  \n",
       "0       1               1  \n",
       "1       1               1  \n",
       "2       1               0  \n",
       "3       1               1  \n",
       "4       0               0  \n",
       "5       0               0  \n",
       "6       1               0  \n",
       "7       1               0  \n",
       "8       1               0  \n",
       "9       1               1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio_complete_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05472611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47704</th>\n",
       "      <td>62309</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>168.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60418</th>\n",
       "      <td>95661</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>174.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59952</th>\n",
       "      <td>99247</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>174.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42325</th>\n",
       "      <td>54173</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>167.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25560</th>\n",
       "      <td>45742</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>41.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58106</th>\n",
       "      <td>39966</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>172.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11773</th>\n",
       "      <td>78343</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>154.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41930</th>\n",
       "      <td>91667</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>166.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15429</th>\n",
       "      <td>24601</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>156.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63326</th>\n",
       "      <td>5973</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>176.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Age  gender  height  weight   BMI  weight_status  \\\n",
       "47704  62309   63       2   168.0    82.0  29.1              3   \n",
       "60418  95661   50       2   174.0    76.0  25.1              3   \n",
       "59952  99247   53       2   174.0    65.0  21.5              2   \n",
       "42325  54173   57       2   167.0    62.0  22.2              2   \n",
       "25560  45742   40       1   160.0   106.0  41.4              4   \n",
       "58106  39966   56       1   172.0    83.0  28.1              3   \n",
       "11773  78343   45       1   154.0    65.0  27.4              3   \n",
       "41930  91667   61       2   166.0    90.0  32.7              4   \n",
       "15429  24601   61       1   156.0    82.0  33.7              4   \n",
       "63326   5973   39       2   176.0    78.0  25.2              3   \n",
       "\n",
       "       obesity_status  systolic_bp  diastolic_bp  cholesterol  glucose  \\\n",
       "47704               1        130.0          80.0            1        1   \n",
       "60418               0        130.0          80.0            1        1   \n",
       "59952               0        180.0          90.0            1        1   \n",
       "42325               0        130.0          80.0            1        1   \n",
       "25560               1        130.0          80.0            1        1   \n",
       "58106               0        110.0          80.0            3        1   \n",
       "11773               0        140.0         100.0            1        1   \n",
       "41930               1        120.0          80.0            1        1   \n",
       "15429               1        130.0          80.0            1        1   \n",
       "63326               0        120.0          80.0            1        1   \n",
       "\n",
       "       smoker  alcohol_intake  active  cardio_disease  \n",
       "47704       1               0       1               0  \n",
       "60418       1               0       1               1  \n",
       "59952       0               0       1               1  \n",
       "42325       0               0       1               1  \n",
       "25560       0               0       1               0  \n",
       "58106       0               0       1               1  \n",
       "11773       0               0       0               0  \n",
       "41930       1               0       0               1  \n",
       "15429       0               0       1               0  \n",
       "63326       1               1       1               0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio_complete_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cd6b54",
   "metadata": {},
   "source": [
    "## Pre processing data for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da251fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  gender  weight   BMI  weight_status  obesity_status  systolic_bp  \\\n",
       "0   51       1    29.0   9.9              1               0        110.0   \n",
       "1   49       1    30.0  11.7              1               0        120.0   \n",
       "2   58       1    30.0  14.7              1               0        103.0   \n",
       "3   47       2    31.0  10.7              1               0        150.0   \n",
       "4   42       1    32.0  15.0              1               0        100.0   \n",
       "\n",
       "   diastolic_bp  cholesterol  glucose  smoker  alcohol_intake  active  \\\n",
       "0          70.0            2        1       0               0       1   \n",
       "1          80.0            1        1       0               0       1   \n",
       "2          61.0            2        1       0               0       1   \n",
       "3          90.0            2        2       0               0       1   \n",
       "4          70.0            1        1       0               0       0   \n",
       "\n",
       "   cardio_disease  \n",
       "0               1  \n",
       "1               1  \n",
       "2               0  \n",
       "3               1  \n",
       "4               0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID , height columns.\n",
    "cardio_processed_df = cardio_complete_df.drop([\"id\",\"height\"], axis =1)\n",
    "cardio_processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d9b3658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51222, 13)\n",
      "(17075, 13)\n",
      "(51222,)\n",
      "(17075,)\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = cardio_processed_df.drop([\"cardio_disease\"],1).values\n",
    "y = cardio_processed_df[\"cardio_disease\"].values\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 78)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca8ea7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1eb238ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 500)               7000      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 192,501\n",
      "Trainable params: 192,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  500\n",
    "hidden_nodes_layer2 = 300\n",
    "hidden_nodes_layer3 = 100\n",
    "hidden_nodes_layer4 = 50\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27a416e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c4a85539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1601/1601 [==============================] - 3s 1ms/step - loss: 0.5561 - accuracy: 0.7265\n",
      "Epoch 2/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7325\n",
      "Epoch 3/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5470 - accuracy: 0.7319\n",
      "Epoch 4/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5458 - accuracy: 0.7333\n",
      "Epoch 5/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5443 - accuracy: 0.7347\n",
      "Epoch 6/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7346\n",
      "Epoch 7/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5424 - accuracy: 0.7361\n",
      "Epoch 8/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5418 - accuracy: 0.7358\n",
      "Epoch 9/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5413 - accuracy: 0.7362\n",
      "Epoch 10/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5400 - accuracy: 0.7377\n",
      "Epoch 11/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5398 - accuracy: 0.7375\n",
      "Epoch 12/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5390 - accuracy: 0.7390\n",
      "Epoch 13/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5379 - accuracy: 0.7407\n",
      "Epoch 14/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7394\n",
      "Epoch 15/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5360 - accuracy: 0.7411\n",
      "Epoch 16/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5356 - accuracy: 0.7400\n",
      "Epoch 17/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5343 - accuracy: 0.7424\n",
      "Epoch 18/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5328 - accuracy: 0.7429\n",
      "Epoch 19/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5325 - accuracy: 0.7422\n",
      "Epoch 20/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5304 - accuracy: 0.7450\n",
      "Epoch 21/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5294 - accuracy: 0.7456\n",
      "Epoch 22/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5273 - accuracy: 0.7451\n",
      "Epoch 23/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5264 - accuracy: 0.7461\n",
      "Epoch 24/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5254 - accuracy: 0.7457\n",
      "Epoch 25/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5234 - accuracy: 0.7480\n",
      "Epoch 26/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5215 - accuracy: 0.7491\n",
      "Epoch 27/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5195 - accuracy: 0.7513\n",
      "Epoch 28/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5181 - accuracy: 0.7509\n",
      "Epoch 29/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5166 - accuracy: 0.7517\n",
      "Epoch 30/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5138 - accuracy: 0.7525\n",
      "Epoch 31/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5127 - accuracy: 0.7536\n",
      "Epoch 32/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5103 - accuracy: 0.7535\n",
      "Epoch 33/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5081 - accuracy: 0.7559\n",
      "Epoch 34/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5063 - accuracy: 0.7578\n",
      "Epoch 35/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5042 - accuracy: 0.7580\n",
      "Epoch 36/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5016 - accuracy: 0.7599\n",
      "Epoch 37/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4996 - accuracy: 0.7608\n",
      "Epoch 38/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4975 - accuracy: 0.7616\n",
      "Epoch 39/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4958 - accuracy: 0.7638\n",
      "Epoch 40/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4940 - accuracy: 0.7649\n",
      "Epoch 41/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4925 - accuracy: 0.7631\n",
      "Epoch 42/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4892 - accuracy: 0.7661\n",
      "Epoch 43/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4869 - accuracy: 0.7672\n",
      "Epoch 44/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4857 - accuracy: 0.7671\n",
      "Epoch 45/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4838 - accuracy: 0.7691\n",
      "Epoch 46/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4819 - accuracy: 0.7708\n",
      "Epoch 47/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4790 - accuracy: 0.7720\n",
      "Epoch 48/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4771 - accuracy: 0.7724\n",
      "Epoch 49/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4764 - accuracy: 0.7728\n",
      "Epoch 50/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4724 - accuracy: 0.7742\n",
      "Epoch 51/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4711 - accuracy: 0.7753\n",
      "Epoch 52/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4710 - accuracy: 0.7759\n",
      "Epoch 53/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4685 - accuracy: 0.7766\n",
      "Epoch 54/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4661 - accuracy: 0.7780\n",
      "Epoch 55/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4652 - accuracy: 0.7778\n",
      "Epoch 56/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4629 - accuracy: 0.7793\n",
      "Epoch 57/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4615 - accuracy: 0.7798\n",
      "Epoch 58/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4589 - accuracy: 0.7811\n",
      "Epoch 59/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4576 - accuracy: 0.7821\n",
      "Epoch 60/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4579 - accuracy: 0.7819\n",
      "Epoch 61/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4520 - accuracy: 0.7851\n",
      "Epoch 62/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4565 - accuracy: 0.7831\n",
      "Epoch 63/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4528 - accuracy: 0.7848\n",
      "Epoch 64/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4500 - accuracy: 0.7855\n",
      "Epoch 65/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4499 - accuracy: 0.7860\n",
      "Epoch 66/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4464 - accuracy: 0.7879\n",
      "Epoch 67/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4460 - accuracy: 0.7871\n",
      "Epoch 68/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4458 - accuracy: 0.7877\n",
      "Epoch 69/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4417 - accuracy: 0.7900\n",
      "Epoch 70/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4426 - accuracy: 0.7902\n",
      "Epoch 71/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4394 - accuracy: 0.7909\n",
      "Epoch 72/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4361 - accuracy: 0.7915\n",
      "Epoch 73/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4374 - accuracy: 0.7907\n",
      "Epoch 74/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4351 - accuracy: 0.7926\n",
      "Epoch 75/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4328 - accuracy: 0.7940\n",
      "Epoch 76/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4328 - accuracy: 0.7939\n",
      "Epoch 77/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4352 - accuracy: 0.7941\n",
      "Epoch 78/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4277 - accuracy: 0.7959\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4273 - accuracy: 0.7975\n",
      "Epoch 80/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4273 - accuracy: 0.7965\n",
      "Epoch 81/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4304 - accuracy: 0.7954\n",
      "Epoch 82/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4241 - accuracy: 0.7981\n",
      "Epoch 83/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4233 - accuracy: 0.7986\n",
      "Epoch 84/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4240 - accuracy: 0.7992\n",
      "Epoch 85/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4196 - accuracy: 0.8011\n",
      "Epoch 86/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4194 - accuracy: 0.8013\n",
      "Epoch 87/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4196 - accuracy: 0.8008\n",
      "Epoch 88/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4179 - accuracy: 0.8015\n",
      "Epoch 89/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4171 - accuracy: 0.8017\n",
      "Epoch 90/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4166 - accuracy: 0.8027\n",
      "Epoch 91/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4180 - accuracy: 0.8031\n",
      "Epoch 92/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4131 - accuracy: 0.8042\n",
      "Epoch 93/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4149 - accuracy: 0.8044\n",
      "Epoch 94/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4109 - accuracy: 0.8049\n",
      "Epoch 95/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4103 - accuracy: 0.8048\n",
      "Epoch 96/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4075 - accuracy: 0.8066\n",
      "Epoch 97/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4078 - accuracy: 0.8070\n",
      "Epoch 98/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4062 - accuracy: 0.8066\n",
      "Epoch 99/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4070 - accuracy: 0.8084\n",
      "Epoch 100/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4020 - accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "175e2b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b7a6990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f423e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 - 0s - loss: 1.1123 - accuracy: 0.7064\n",
      "Loss: 1.112, Accuracy: 0.706\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {(model_loss):.3f}, Accuracy: {(model_accuracy):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f177e4",
   "metadata": {},
   "source": [
    "## \"The accuracy of this model is 71.0% after adding additional neurons to each of the 4 hidden layers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87905049",
   "metadata": {},
   "source": [
    "## Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3336301b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 500)               7000      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 192,501\n",
      "Trainable params: 192,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 500\n",
    "hidden_nodes_layer2 = 300\n",
    "hidden_nodes_layer3 = 100\n",
    "hidden_nodes_layer4 = 50\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf6a9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb5f876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5559 - accuracy: 0.7284\n",
      "Epoch 2/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7303\n",
      "Epoch 3/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5472 - accuracy: 0.7330\n",
      "Epoch 4/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5455 - accuracy: 0.7333\n",
      "Epoch 5/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7352\n",
      "Epoch 6/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5437 - accuracy: 0.7347\n",
      "Epoch 7/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5428 - accuracy: 0.7349\n",
      "Epoch 8/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5419 - accuracy: 0.7354\n",
      "Epoch 9/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5413 - accuracy: 0.7364\n",
      "Epoch 10/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5410 - accuracy: 0.7372\n",
      "Epoch 11/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5398 - accuracy: 0.7388\n",
      "Epoch 12/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5392 - accuracy: 0.7379\n",
      "Epoch 13/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5383 - accuracy: 0.7388\n",
      "Epoch 14/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5378 - accuracy: 0.7393\n",
      "Epoch 15/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5369 - accuracy: 0.7403\n",
      "Epoch 16/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5359 - accuracy: 0.7399\n",
      "Epoch 17/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5352 - accuracy: 0.7413\n",
      "Epoch 18/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5338 - accuracy: 0.7417\n",
      "Epoch 19/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5329 - accuracy: 0.7419\n",
      "Epoch 20/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5311 - accuracy: 0.7432\n",
      "Epoch 21/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5304 - accuracy: 0.7433\n",
      "Epoch 22/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5286 - accuracy: 0.7443\n",
      "Epoch 23/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5266 - accuracy: 0.7458\n",
      "Epoch 24/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5254 - accuracy: 0.7465\n",
      "Epoch 25/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5231 - accuracy: 0.7480\n",
      "Epoch 26/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5221 - accuracy: 0.7485\n",
      "Epoch 27/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5201 - accuracy: 0.7498\n",
      "Epoch 28/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5175 - accuracy: 0.7508\n",
      "Epoch 29/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5156 - accuracy: 0.7512\n",
      "Epoch 30/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5142 - accuracy: 0.7521\n",
      "Epoch 31/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5123 - accuracy: 0.7535\n",
      "Epoch 32/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5097 - accuracy: 0.7552\n",
      "Epoch 33/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5077 - accuracy: 0.7559\n",
      "Epoch 34/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.5060 - accuracy: 0.7567\n",
      "Epoch 35/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5038 - accuracy: 0.7589\n",
      "Epoch 36/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.5016 - accuracy: 0.7593\n",
      "Epoch 37/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4990 - accuracy: 0.7611\n",
      "Epoch 38/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4976 - accuracy: 0.7618\n",
      "Epoch 39/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4951 - accuracy: 0.7622\n",
      "Epoch 40/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4946 - accuracy: 0.7629\n",
      "Epoch 41/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4922 - accuracy: 0.7640\n",
      "Epoch 42/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4885 - accuracy: 0.7663\n",
      "Epoch 43/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4878 - accuracy: 0.7674\n",
      "Epoch 44/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4848 - accuracy: 0.7698\n",
      "Epoch 45/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4826 - accuracy: 0.7699\n",
      "Epoch 46/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4812 - accuracy: 0.7702\n",
      "Epoch 47/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4784 - accuracy: 0.7704\n",
      "Epoch 48/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4776 - accuracy: 0.7710\n",
      "Epoch 49/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4749 - accuracy: 0.7728\n",
      "Epoch 50/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4725 - accuracy: 0.7742\n",
      "Epoch 51/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4723 - accuracy: 0.7743\n",
      "Epoch 52/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4702 - accuracy: 0.7760\n",
      "Epoch 53/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4683 - accuracy: 0.7771\n",
      "Epoch 54/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4669 - accuracy: 0.7768\n",
      "Epoch 55/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4637 - accuracy: 0.7797\n",
      "Epoch 56/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4631 - accuracy: 0.7798\n",
      "Epoch 57/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4586 - accuracy: 0.7805\n",
      "Epoch 58/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4582 - accuracy: 0.7818\n",
      "Epoch 59/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4579 - accuracy: 0.7826\n",
      "Epoch 60/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4542 - accuracy: 0.7840\n",
      "Epoch 61/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4540 - accuracy: 0.7843\n",
      "Epoch 62/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4526 - accuracy: 0.7838\n",
      "Epoch 63/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4515 - accuracy: 0.7848\n",
      "Epoch 64/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4478 - accuracy: 0.7865\n",
      "Epoch 65/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4463 - accuracy: 0.7872\n",
      "Epoch 66/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4481 - accuracy: 0.7869\n",
      "Epoch 67/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4453 - accuracy: 0.7879\n",
      "Epoch 68/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4433 - accuracy: 0.7883\n",
      "Epoch 69/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4404 - accuracy: 0.7899\n",
      "Epoch 70/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4398 - accuracy: 0.7898\n",
      "Epoch 71/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4376 - accuracy: 0.7915\n",
      "Epoch 72/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4378 - accuracy: 0.7917\n",
      "Epoch 73/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4360 - accuracy: 0.7923\n",
      "Epoch 74/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4336 - accuracy: 0.7934\n",
      "Epoch 75/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4332 - accuracy: 0.7930\n",
      "Epoch 76/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4313 - accuracy: 0.7945\n",
      "Epoch 77/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4302 - accuracy: 0.7948\n",
      "Epoch 78/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4287 - accuracy: 0.7955\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4269 - accuracy: 0.7970\n",
      "Epoch 80/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4232 - accuracy: 0.7983\n",
      "Epoch 81/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4265 - accuracy: 0.7965\n",
      "Epoch 82/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4253 - accuracy: 0.7978\n",
      "Epoch 83/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4206 - accuracy: 0.7997\n",
      "Epoch 84/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4207 - accuracy: 0.7997\n",
      "Epoch 85/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4173 - accuracy: 0.8016\n",
      "Epoch 86/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4178 - accuracy: 0.8012\n",
      "Epoch 87/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4168 - accuracy: 0.8024\n",
      "Epoch 88/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4166 - accuracy: 0.8023\n",
      "Epoch 89/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4156 - accuracy: 0.8024\n",
      "Epoch 90/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4129 - accuracy: 0.8034\n",
      "Epoch 91/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4095 - accuracy: 0.8060\n",
      "Epoch 92/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4120 - accuracy: 0.8041\n",
      "Epoch 93/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4109 - accuracy: 0.8048\n",
      "Epoch 94/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4079 - accuracy: 0.8070\n",
      "Epoch 95/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4125 - accuracy: 0.8052\n",
      "Epoch 96/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4082 - accuracy: 0.8073\n",
      "Epoch 97/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4084 - accuracy: 0.8077\n",
      "Epoch 98/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4041 - accuracy: 0.8084\n",
      "Epoch 99/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4047 - accuracy: 0.8074\n",
      "Epoch 100/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4011 - accuracy: 0.8084\n",
      "Epoch 101/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4034 - accuracy: 0.8081\n",
      "Epoch 102/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4015 - accuracy: 0.8095\n",
      "Epoch 103/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4010 - accuracy: 0.8099\n",
      "Epoch 104/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3968 - accuracy: 0.8120\n",
      "Epoch 105/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3958 - accuracy: 0.8114\n",
      "Epoch 106/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3970 - accuracy: 0.8122\n",
      "Epoch 107/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3984 - accuracy: 0.8115\n",
      "Epoch 108/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3947 - accuracy: 0.8132\n",
      "Epoch 109/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3926 - accuracy: 0.8145\n",
      "Epoch 110/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3903 - accuracy: 0.8143\n",
      "Epoch 111/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3914 - accuracy: 0.8136\n",
      "Epoch 112/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3934 - accuracy: 0.8145\n",
      "Epoch 113/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3859 - accuracy: 0.8157\n",
      "Epoch 114/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3897 - accuracy: 0.8157\n",
      "Epoch 115/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3887 - accuracy: 0.8157\n",
      "Epoch 116/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3845 - accuracy: 0.8173\n",
      "Epoch 117/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3869 - accuracy: 0.8158\n",
      "Epoch 118/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3875 - accuracy: 0.8158\n",
      "Epoch 119/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3807 - accuracy: 0.8189\n",
      "Epoch 120/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3850 - accuracy: 0.8171\n",
      "Epoch 121/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3805 - accuracy: 0.8198\n",
      "Epoch 122/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3809 - accuracy: 0.8186\n",
      "Epoch 123/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3838 - accuracy: 0.8186\n",
      "Epoch 124/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3826 - accuracy: 0.8191\n",
      "Epoch 125/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3769 - accuracy: 0.8197\n",
      "Epoch 126/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3780 - accuracy: 0.8218\n",
      "Epoch 127/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3792 - accuracy: 0.8197\n",
      "Epoch 128/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3754 - accuracy: 0.8225\n",
      "Epoch 129/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3729 - accuracy: 0.8225\n",
      "Epoch 130/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3784 - accuracy: 0.8213\n",
      "Epoch 131/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3714 - accuracy: 0.8238\n",
      "Epoch 132/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3748 - accuracy: 0.8224\n",
      "Epoch 133/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3754 - accuracy: 0.8230\n",
      "Epoch 134/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3699 - accuracy: 0.8245\n",
      "Epoch 135/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3702 - accuracy: 0.8241\n",
      "Epoch 136/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3697 - accuracy: 0.8255\n",
      "Epoch 137/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3704 - accuracy: 0.8251\n",
      "Epoch 138/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3670 - accuracy: 0.8266\n",
      "Epoch 139/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3684 - accuracy: 0.8253\n",
      "Epoch 140/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3659 - accuracy: 0.8265\n",
      "Epoch 141/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3676 - accuracy: 0.8267\n",
      "Epoch 142/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3626 - accuracy: 0.8286\n",
      "Epoch 143/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3677 - accuracy: 0.8273\n",
      "Epoch 144/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3642 - accuracy: 0.8285\n",
      "Epoch 145/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3623 - accuracy: 0.8286\n",
      "Epoch 146/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3628 - accuracy: 0.8284\n",
      "Epoch 147/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3632 - accuracy: 0.8287\n",
      "Epoch 148/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3618 - accuracy: 0.8287\n",
      "Epoch 149/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3623 - accuracy: 0.8281\n",
      "Epoch 150/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3575 - accuracy: 0.8316\n",
      "Epoch 151/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3591 - accuracy: 0.8299\n",
      "Epoch 152/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3574 - accuracy: 0.8315\n",
      "Epoch 153/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3590 - accuracy: 0.8311\n",
      "Epoch 154/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3619 - accuracy: 0.8293\n",
      "Epoch 155/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3572 - accuracy: 0.8311\n",
      "Epoch 156/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3508 - accuracy: 0.8336\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3566 - accuracy: 0.8330\n",
      "Epoch 158/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3504 - accuracy: 0.8332\n",
      "Epoch 159/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3564 - accuracy: 0.8331\n",
      "Epoch 160/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3532 - accuracy: 0.8329\n",
      "Epoch 161/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3605 - accuracy: 0.8319\n",
      "Epoch 162/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3508 - accuracy: 0.8343\n",
      "Epoch 163/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3525 - accuracy: 0.8343\n",
      "Epoch 164/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3535 - accuracy: 0.8351\n",
      "Epoch 165/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3509 - accuracy: 0.8353\n",
      "Epoch 166/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3499 - accuracy: 0.8339\n",
      "Epoch 167/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3495 - accuracy: 0.8361\n",
      "Epoch 168/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3475 - accuracy: 0.8360\n",
      "Epoch 169/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3475 - accuracy: 0.8357\n",
      "Epoch 170/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3474 - accuracy: 0.8363\n",
      "Epoch 171/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3452 - accuracy: 0.8370\n",
      "Epoch 172/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3494 - accuracy: 0.8352\n",
      "Epoch 173/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3452 - accuracy: 0.8376\n",
      "Epoch 174/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3415 - accuracy: 0.8393\n",
      "Epoch 175/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3477 - accuracy: 0.8363\n",
      "Epoch 176/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3445 - accuracy: 0.8384\n",
      "Epoch 177/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3441 - accuracy: 0.8392\n",
      "Epoch 178/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3430 - accuracy: 0.8382\n",
      "Epoch 179/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3434 - accuracy: 0.8383\n",
      "Epoch 180/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3426 - accuracy: 0.8392\n",
      "Epoch 181/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3421 - accuracy: 0.8386\n",
      "Epoch 182/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3384 - accuracy: 0.8408\n",
      "Epoch 183/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3398 - accuracy: 0.8403\n",
      "Epoch 184/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3405 - accuracy: 0.8404\n",
      "Epoch 185/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3449 - accuracy: 0.8392\n",
      "Epoch 186/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3397 - accuracy: 0.8411\n",
      "Epoch 187/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3383 - accuracy: 0.8413\n",
      "Epoch 188/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3353 - accuracy: 0.8409\n",
      "Epoch 189/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3393 - accuracy: 0.8401\n",
      "Epoch 190/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3389 - accuracy: 0.8410\n",
      "Epoch 191/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3356 - accuracy: 0.8423\n",
      "Epoch 192/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3337 - accuracy: 0.8436\n",
      "Epoch 193/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3350 - accuracy: 0.8434\n",
      "Epoch 194/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3345 - accuracy: 0.8418\n",
      "Epoch 195/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3338 - accuracy: 0.8438\n",
      "Epoch 196/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3312 - accuracy: 0.8448\n",
      "Epoch 197/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3309 - accuracy: 0.8439\n",
      "Epoch 198/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3315 - accuracy: 0.8429\n",
      "Epoch 199/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3367 - accuracy: 0.8410\n",
      "Epoch 200/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3294 - accuracy: 0.8443\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c83f828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 - 0s - loss: 1.6407 - accuracy: 0.6959\n",
      "Loss: 1.641, Accuracy: 0.696\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {(model_loss):.3f}, Accuracy: {(model_accuracy):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9b9190",
   "metadata": {},
   "source": [
    "## The accuracy is 70% after adding additional neurons to the 4 hidden layers and epoch of 200. This looks like a classic case of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5038b6",
   "metadata": {},
   "source": [
    "### Trial 3 with 5 hidden layers and optimizer as \"rmsprop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ca6a883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 700)               9800      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 490,801\n",
      "Trainable params: 490,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 700\n",
    "hidden_nodes_layer2 = 500\n",
    "hidden_nodes_layer3 = 200\n",
    "hidden_nodes_layer4 = 100\n",
    "hidden_nodes_layer5 = 50\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09664e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer =\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0cec15bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5603 - accuracy: 0.7258\n",
      "Epoch 2/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5528 - accuracy: 0.7307\n",
      "Epoch 3/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5507 - accuracy: 0.7317\n",
      "Epoch 4/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5487 - accuracy: 0.7336\n",
      "Epoch 5/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5482 - accuracy: 0.7331\n",
      "Epoch 6/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5469 - accuracy: 0.7340\n",
      "Epoch 7/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5462 - accuracy: 0.7355\n",
      "Epoch 8/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5464 - accuracy: 0.7349\n",
      "Epoch 9/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5460 - accuracy: 0.7352\n",
      "Epoch 10/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5473 - accuracy: 0.7355\n",
      "Epoch 11/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5465 - accuracy: 0.7365\n",
      "Epoch 12/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5470 - accuracy: 0.7353\n",
      "Epoch 13/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5459 - accuracy: 0.7354\n",
      "Epoch 14/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5466 - accuracy: 0.7353\n",
      "Epoch 15/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5479 - accuracy: 0.7359\n",
      "Epoch 16/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5472 - accuracy: 0.7352\n",
      "Epoch 17/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5481 - accuracy: 0.7342\n",
      "Epoch 18/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5475 - accuracy: 0.7356\n",
      "Epoch 19/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5481 - accuracy: 0.7348\n",
      "Epoch 20/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5482 - accuracy: 0.7354\n",
      "Epoch 21/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5493 - accuracy: 0.7349\n",
      "Epoch 22/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5488 - accuracy: 0.7339\n",
      "Epoch 23/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5485 - accuracy: 0.7329\n",
      "Epoch 24/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5479 - accuracy: 0.7343\n",
      "Epoch 25/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5487 - accuracy: 0.7353\n",
      "Epoch 26/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5484 - accuracy: 0.7345\n",
      "Epoch 27/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5507 - accuracy: 0.7348\n",
      "Epoch 28/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5482 - accuracy: 0.7353\n",
      "Epoch 29/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5504 - accuracy: 0.7334\n",
      "Epoch 30/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5505 - accuracy: 0.7355\n",
      "Epoch 31/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5500 - accuracy: 0.7355\n",
      "Epoch 32/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5500 - accuracy: 0.7353\n",
      "Epoch 33/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5540 - accuracy: 0.7335\n",
      "Epoch 34/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5513 - accuracy: 0.7345\n",
      "Epoch 35/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5522 - accuracy: 0.7353\n",
      "Epoch 36/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5509 - accuracy: 0.7348\n",
      "Epoch 37/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5532 - accuracy: 0.7356\n",
      "Epoch 38/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5566 - accuracy: 0.7356\n",
      "Epoch 39/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5508 - accuracy: 0.7360\n",
      "Epoch 40/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5546 - accuracy: 0.7362\n",
      "Epoch 41/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5516 - accuracy: 0.7347\n",
      "Epoch 42/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5554 - accuracy: 0.7347\n",
      "Epoch 43/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5529 - accuracy: 0.7361\n",
      "Epoch 44/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5520 - accuracy: 0.7372\n",
      "Epoch 45/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5531 - accuracy: 0.7368\n",
      "Epoch 46/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5532 - accuracy: 0.7368\n",
      "Epoch 47/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5523 - accuracy: 0.7367\n",
      "Epoch 48/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5512 - accuracy: 0.7379\n",
      "Epoch 49/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5501 - accuracy: 0.7377\n",
      "Epoch 50/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5513 - accuracy: 0.7361\n",
      "Epoch 51/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5514 - accuracy: 0.7363\n",
      "Epoch 52/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5477 - accuracy: 0.7374\n",
      "Epoch 53/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5510 - accuracy: 0.7382\n",
      "Epoch 54/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5495 - accuracy: 0.7385\n",
      "Epoch 55/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5497 - accuracy: 0.7366\n",
      "Epoch 56/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5499 - accuracy: 0.7390\n",
      "Epoch 57/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5492 - accuracy: 0.7394\n",
      "Epoch 58/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5482 - accuracy: 0.7375\n",
      "Epoch 59/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5520 - accuracy: 0.7380\n",
      "Epoch 60/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5531 - accuracy: 0.7384\n",
      "Epoch 61/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5504 - accuracy: 0.7385\n",
      "Epoch 62/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5498 - accuracy: 0.7388\n",
      "Epoch 63/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5502 - accuracy: 0.7385\n",
      "Epoch 64/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5501 - accuracy: 0.7378\n",
      "Epoch 65/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5509 - accuracy: 0.7379\n",
      "Epoch 66/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5491 - accuracy: 0.7387\n",
      "Epoch 67/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5491 - accuracy: 0.7401\n",
      "Epoch 68/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5469 - accuracy: 0.7391\n",
      "Epoch 69/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5499 - accuracy: 0.7392\n",
      "Epoch 70/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5511 - accuracy: 0.7381\n",
      "Epoch 71/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5481 - accuracy: 0.7382\n",
      "Epoch 72/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5485 - accuracy: 0.7398\n",
      "Epoch 73/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5494 - accuracy: 0.7399\n",
      "Epoch 74/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5539 - accuracy: 0.7395\n",
      "Epoch 75/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5491 - accuracy: 0.7401\n",
      "Epoch 76/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5526 - accuracy: 0.7405\n",
      "Epoch 77/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5478 - accuracy: 0.7402\n",
      "Epoch 78/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5505 - accuracy: 0.7412\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5485 - accuracy: 0.7394\n",
      "Epoch 80/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5493 - accuracy: 0.7395\n",
      "Epoch 81/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5542 - accuracy: 0.7391\n",
      "Epoch 82/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5494 - accuracy: 0.7395\n",
      "Epoch 83/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5461 - accuracy: 0.7394\n",
      "Epoch 84/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5567 - accuracy: 0.7396\n",
      "Epoch 85/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5519 - accuracy: 0.7396\n",
      "Epoch 86/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5497 - accuracy: 0.7405\n",
      "Epoch 87/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5544 - accuracy: 0.7406\n",
      "Epoch 88/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5483 - accuracy: 0.7414\n",
      "Epoch 89/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5513 - accuracy: 0.7410\n",
      "Epoch 90/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5518 - accuracy: 0.7425\n",
      "Epoch 91/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5454 - accuracy: 0.7419\n",
      "Epoch 92/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5498 - accuracy: 0.7419\n",
      "Epoch 93/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5536 - accuracy: 0.7411\n",
      "Epoch 94/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5491 - accuracy: 0.7424\n",
      "Epoch 95/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5487 - accuracy: 0.7414\n",
      "Epoch 96/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5485 - accuracy: 0.7423\n",
      "Epoch 97/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5477 - accuracy: 0.7416\n",
      "Epoch 98/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5513 - accuracy: 0.7418\n",
      "Epoch 99/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5474 - accuracy: 0.7419\n",
      "Epoch 100/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5469 - accuracy: 0.7425\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c45dd009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 - 0s - loss: 0.5834 - accuracy: 0.7310\n",
      "Loss: 0.583, Accuracy: 0.731\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {(model_loss):.3f}, Accuracy: {(model_accuracy):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecff2079",
   "metadata": {},
   "source": [
    "## \"The accuracy of this model is 73.0% after adding additional neurons to each of the 4 hidden layers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b9df40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
