{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad64256c",
   "metadata": {},
   "source": [
    "## Deep learning on Be heart Smart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f3eb648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All neccessary libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "# Import Username,Password and Database_name\n",
    "from config import Username,Password,DBname\n",
    "print(\"All neccessary libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c916409",
   "metadata": {},
   "source": [
    "## Creating Connection to Be Heart Smart Db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8afcfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The create_engine() function produces an Engine object based on a URL\n",
    "engine = create_engine('postgresql+psycopg2://postgres:'+ Password + '@localhost:5432/' + DBname)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1e0b4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26503.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54851.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21040.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47872.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23318.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   age  gender  height  weight  systolic_bp  diastolic_bp  \\\n",
       "0  26503.0  49.0     1.0   160.0    30.0        120.0          80.0   \n",
       "1  54851.0  59.0     1.0   154.0    32.0        110.0          60.0   \n",
       "2  21040.0  62.0     1.0   143.0    34.0        100.0          70.0   \n",
       "3  47872.0  57.0     1.0   153.0    34.0        110.0          70.0   \n",
       "4  23318.0  59.0     1.0   165.0    35.0        100.0          70.0   \n",
       "\n",
       "   cholesterol  glucose  smoker  alcohol_intake  active  cardio_disease   bmi  \\\n",
       "0          1.0      1.0     0.0             0.0     1.0             1.0  11.7   \n",
       "1          1.0      1.0     0.0             0.0     1.0             0.0  13.5   \n",
       "2          1.0      1.0     0.0             0.0     1.0             0.0  16.6   \n",
       "3          3.0      3.0     0.0             0.0     1.0             1.0  14.5   \n",
       "4          1.0      1.0     0.0             0.0     1.0             0.0  12.9   \n",
       "\n",
       "  weight_status obesity_status  \n",
       "0   underweight             no  \n",
       "1   underweight             no  \n",
       "2   underweight             no  \n",
       "3   underweight             no  \n",
       "4   underweight             no  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create cardio dataframe from cardio data cleaned table in the database\n",
    "cardio_complete_df = pd.read_sql(\"SELECT * FROM cardio_complete\",connection)\n",
    "cardio_complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ac9448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86650</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26503</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59853</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24167</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>170.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31439</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>146.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Age  gender  height  weight  systolic_bp  diastolic_bp  cholesterol  \\\n",
       "0  86650   51       1   171.0    29.0        110.0          70.0            2   \n",
       "1  26503   49       1   160.0    30.0        120.0          80.0            1   \n",
       "2  59853   58       1   143.0    30.0        103.0          61.0            2   \n",
       "3  24167   47       2   170.0    31.0        150.0          90.0            2   \n",
       "4  31439   42       1   146.0    32.0        100.0          70.0            1   \n",
       "\n",
       "   glucose  smoker  alcohol_intake  active  cardio_disease  \n",
       "0        1       0               0       1               1  \n",
       "1        1       0               0       1               1  \n",
       "2        1       0               0       1               0  \n",
       "3        2       0               0       1               1  \n",
       "4        1       0               0       0               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the cardio data to a dataframe\n",
    "path = ('../Resources/cardio_cleaned.csv')\n",
    "cardio_df = pd.read_csv(path)  \n",
    "cardio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8feb4a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86650</td>\n",
       "      <td>9.9</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26503</td>\n",
       "      <td>11.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59853</td>\n",
       "      <td>14.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24167</td>\n",
       "      <td>10.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31439</td>\n",
       "      <td>15.0</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   BMI weight_status obesity_status\n",
       "0  86650   9.9   underweight             no\n",
       "1  26503  11.7   underweight             no\n",
       "2  59853  14.7   underweight             no\n",
       "3  24167  10.7   underweight             no\n",
       "4  31439  15.0   underweight             no"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the BMI data to a dataframe\n",
    "path = ('../Resources/BMI.csv')\n",
    "BMI_df = pd.read_csv(path)  \n",
    "BMI_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f27a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86650</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26503</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59853</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24167</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>170.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31439</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>146.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Age  gender  height  weight  systolic_bp  diastolic_bp  cholesterol  \\\n",
       "0  86650   51       1   171.0    29.0        110.0          70.0            2   \n",
       "1  26503   49       1   160.0    30.0        120.0          80.0            1   \n",
       "2  59853   58       1   143.0    30.0        103.0          61.0            2   \n",
       "3  24167   47       2   170.0    31.0        150.0          90.0            2   \n",
       "4  31439   42       1   146.0    32.0        100.0          70.0            1   \n",
       "\n",
       "   glucose  smoker  alcohol_intake  active  cardio_disease   BMI  \\\n",
       "0        1       0               0       1               1   9.9   \n",
       "1        1       0               0       1               1  11.7   \n",
       "2        1       0               0       1               0  14.7   \n",
       "3        2       0               0       1               1  10.7   \n",
       "4        1       0               0       0               0  15.0   \n",
       "\n",
       "  weight_status obesity_status  \n",
       "0   underweight             no  \n",
       "1   underweight             no  \n",
       "2   underweight             no  \n",
       "3   underweight             no  \n",
       "4   underweight             no  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two DataFrames on id.\n",
    "cardio_complete_df = pd.merge(cardio_df, BMI_df, on=\"id\")\n",
    "cardio_complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6592374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68297, 16)\n",
      "id                  int64\n",
      "Age                 int64\n",
      "gender              int64\n",
      "height            float64\n",
      "weight            float64\n",
      "systolic_bp       float64\n",
      "diastolic_bp      float64\n",
      "cholesterol         int64\n",
      "glucose             int64\n",
      "smoker              int64\n",
      "alcohol_intake      int64\n",
      "active              int64\n",
      "cardio_disease      int64\n",
      "BMI               float64\n",
      "weight_status      object\n",
      "obesity_status     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(cardio_complete_df.shape)\n",
    "print(cardio_complete_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a072654a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86650</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26503</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59853</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24167</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>170.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31439</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>146.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>underweight</td>\n",
       "      <td>no</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Age  gender  height  weight   BMI weight_status obesity_status  \\\n",
       "0  86650   51       1   171.0    29.0   9.9   underweight             no   \n",
       "1  26503   49       1   160.0    30.0  11.7   underweight             no   \n",
       "2  59853   58       1   143.0    30.0  14.7   underweight             no   \n",
       "3  24167   47       2   170.0    31.0  10.7   underweight             no   \n",
       "4  31439   42       1   146.0    32.0  15.0   underweight             no   \n",
       "\n",
       "   systolic_bp  diastolic_bp  cholesterol  glucose  smoker  alcohol_intake  \\\n",
       "0        110.0          70.0            2        1       0               0   \n",
       "1        120.0          80.0            1        1       0               0   \n",
       "2        103.0          61.0            2        1       0               0   \n",
       "3        150.0          90.0            2        2       0               0   \n",
       "4        100.0          70.0            1        1       0               0   \n",
       "\n",
       "   active  cardio_disease  \n",
       "0       1               1  \n",
       "1       1               1  \n",
       "2       1               0  \n",
       "3       1               1  \n",
       "4       0               0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-aarange columns in the merged DataFrame\n",
    "rearranged_columns = [\"id\", \"Age\", \"gender\", \"height\", \"weight\", \"BMI\", \"weight_status\", \"obesity_status\", \n",
    "                       \"systolic_bp\", \"diastolic_bp\", \"cholesterol\", \"glucose\", \"smoker\", \"alcohol_intake\", \n",
    "                       \"active\", \"cardio_disease\"]\n",
    "cardio_complete_df = cardio_complete_df[rearranged_columns]\n",
    "cardio_complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9308bf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "      <td>68297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49972.437969</td>\n",
       "      <td>52.819304</td>\n",
       "      <td>1.348375</td>\n",
       "      <td>164.452070</td>\n",
       "      <td>74.072282</td>\n",
       "      <td>27.420065</td>\n",
       "      <td>126.351538</td>\n",
       "      <td>81.215983</td>\n",
       "      <td>1.363383</td>\n",
       "      <td>1.225134</td>\n",
       "      <td>0.087778</td>\n",
       "      <td>0.053165</td>\n",
       "      <td>0.803549</td>\n",
       "      <td>0.493272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28851.286589</td>\n",
       "      <td>6.771405</td>\n",
       "      <td>0.476459</td>\n",
       "      <td>7.820924</td>\n",
       "      <td>14.254568</td>\n",
       "      <td>5.184147</td>\n",
       "      <td>16.067301</td>\n",
       "      <td>9.262086</td>\n",
       "      <td>0.678032</td>\n",
       "      <td>0.571167</td>\n",
       "      <td>0.282974</td>\n",
       "      <td>0.224364</td>\n",
       "      <td>0.397316</td>\n",
       "      <td>0.499958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24994.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50017.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>26.300000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74868.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99999.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>85.800000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           Age        gender        height        weight  \\\n",
       "count  68297.000000  68297.000000  68297.000000  68297.000000  68297.000000   \n",
       "mean   49972.437969     52.819304      1.348375    164.452070     74.072282   \n",
       "std    28851.286589      6.771405      0.476459      7.820924     14.254568   \n",
       "min        0.000000     29.000000      1.000000    135.000000     29.000000   \n",
       "25%    24994.000000     48.000000      1.000000    159.000000     65.000000   \n",
       "50%    50017.000000     53.000000      1.000000    165.000000     72.000000   \n",
       "75%    74868.000000     58.000000      2.000000    170.000000     82.000000   \n",
       "max    99999.000000     64.000000      2.000000    207.000000    200.000000   \n",
       "\n",
       "                BMI   systolic_bp  diastolic_bp   cholesterol       glucose  \\\n",
       "count  68297.000000  68297.000000  68297.000000  68297.000000  68297.000000   \n",
       "mean      27.420065    126.351538     81.215983      1.363383      1.225134   \n",
       "std        5.184147     16.067301      9.262086      0.678032      0.571167   \n",
       "min        9.900000     80.000000     40.000000      1.000000      1.000000   \n",
       "25%       23.900000    120.000000     80.000000      1.000000      1.000000   \n",
       "50%       26.300000    120.000000     80.000000      1.000000      1.000000   \n",
       "75%       30.100000    140.000000     90.000000      1.000000      1.000000   \n",
       "max       85.800000    180.000000    120.000000      3.000000      3.000000   \n",
       "\n",
       "             smoker  alcohol_intake        active  cardio_disease  \n",
       "count  68297.000000    68297.000000  68297.000000    68297.000000  \n",
       "mean       0.087778        0.053165      0.803549        0.493272  \n",
       "std        0.282974        0.224364      0.397316        0.499958  \n",
       "min        0.000000        0.000000      0.000000        0.000000  \n",
       "25%        0.000000        0.000000      1.000000        0.000000  \n",
       "50%        0.000000        0.000000      1.000000        0.000000  \n",
       "75%        0.000000        0.000000      1.000000        1.000000  \n",
       "max        1.000000        1.000000      1.000000        1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio_complete_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad33d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the continuous variables weight_status, and obesity_status from string to numeric.\n",
    "# Defining a function string_to_numeric.\n",
    "def string_to_numeric(variable):\n",
    "    if variable == \"underweight\":\n",
    "        return 1\n",
    "    elif variable == \"normal\":\n",
    "        return 2\n",
    "    elif variable == \"overweight\":\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a51938cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function string_to_numeric on column weight_status \n",
    "cardio_complete_df[\"weight_status\"] = cardio_complete_df[\"weight_status\"].apply(string_to_numeric)\n",
    "cardio_complete_df.head()\n",
    "\n",
    "# Change the obesity_status to numeric\n",
    "cardio_complete_df[\"obesity_status\"] = cardio_complete_df[\"obesity_status\"].apply(lambda x: 1 if x == \"yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5544d9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86650</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26503</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59853</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24167</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>170.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31439</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>146.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50443</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>146.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54851</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>154.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68667</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21040</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>143.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>47872</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>153.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Age  gender  height  weight   BMI  weight_status  obesity_status  \\\n",
       "0  86650   51       1   171.0    29.0   9.9              1               0   \n",
       "1  26503   49       1   160.0    30.0  11.7              1               0   \n",
       "2  59853   58       1   143.0    30.0  14.7              1               0   \n",
       "3  24167   47       2   170.0    31.0  10.7              1               0   \n",
       "4  31439   42       1   146.0    32.0  15.0              1               0   \n",
       "5  50443   54       1   146.0    32.0  15.0              1               0   \n",
       "6  54851   59       1   154.0    32.0  13.5              1               0   \n",
       "7  68667   52       1   143.0    33.0  16.1              1               0   \n",
       "8  21040   62       1   143.0    34.0  16.6              1               0   \n",
       "9  47872   57       1   153.0    34.0  14.5              1               0   \n",
       "\n",
       "   systolic_bp  diastolic_bp  cholesterol  glucose  smoker  alcohol_intake  \\\n",
       "0        110.0          70.0            2        1       0               0   \n",
       "1        120.0          80.0            1        1       0               0   \n",
       "2        103.0          61.0            2        1       0               0   \n",
       "3        150.0          90.0            2        2       0               0   \n",
       "4        100.0          70.0            1        1       0               0   \n",
       "5        130.0          80.0            1        2       0               0   \n",
       "6        110.0          60.0            1        1       0               0   \n",
       "7        100.0          60.0            1        1       0               0   \n",
       "8        100.0          70.0            1        1       0               0   \n",
       "9        110.0          70.0            3        3       0               0   \n",
       "\n",
       "   active  cardio_disease  \n",
       "0       1               1  \n",
       "1       1               1  \n",
       "2       1               0  \n",
       "3       1               1  \n",
       "4       0               0  \n",
       "5       0               0  \n",
       "6       1               0  \n",
       "7       1               0  \n",
       "8       1               0  \n",
       "9       1               1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio_complete_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "032efecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5606</th>\n",
       "      <td>92513</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>169.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>76681</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>156.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56271</th>\n",
       "      <td>37112</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>171.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51291</th>\n",
       "      <td>15859</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>170.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30072</th>\n",
       "      <td>5992</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>163.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55474</th>\n",
       "      <td>15757</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>170.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57988</th>\n",
       "      <td>98395</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>172.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47645</th>\n",
       "      <td>75131</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63175</th>\n",
       "      <td>63875</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>176.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38531</th>\n",
       "      <td>26264</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>165.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Age  gender  height  weight   BMI  weight_status  \\\n",
       "5606   92513   39       2   169.0    57.0  20.0              2   \n",
       "2578   76681   56       1   156.0    53.0  21.8              2   \n",
       "56271  37112   59       2   171.0    78.0  26.7              3   \n",
       "51291  15859   55       2   170.0    62.0  21.5              2   \n",
       "30072   5992   59       2   163.0    63.0  23.7              2   \n",
       "55474  15757   55       1   170.0   103.0  35.6              4   \n",
       "57988  98395   59       2   172.0    80.0  27.0              3   \n",
       "47645  75131   55       1   168.0    81.0  28.7              3   \n",
       "63175  63875   54       2   176.0    72.0  23.2              2   \n",
       "38531  26264   57       1   165.0    74.0  27.2              3   \n",
       "\n",
       "       obesity_status  systolic_bp  diastolic_bp  cholesterol  glucose  \\\n",
       "5606                0        110.0          70.0            1        1   \n",
       "2578                0        130.0          90.0            1        1   \n",
       "56271               0        130.0          70.0            3        3   \n",
       "51291               0        120.0          80.0            1        1   \n",
       "30072               0        140.0          80.0            1        1   \n",
       "55474               1        120.0          80.0            3        1   \n",
       "57988               0        130.0          90.0            1        1   \n",
       "47645               0        120.0          80.0            2        1   \n",
       "63175               0        130.0          80.0            1        1   \n",
       "38531               0        120.0          80.0            2        2   \n",
       "\n",
       "       smoker  alcohol_intake  active  cardio_disease  \n",
       "5606        0               0       1               0  \n",
       "2578        0               0       1               1  \n",
       "56271       0               0       0               1  \n",
       "51291       0               1       1               0  \n",
       "30072       0               0       0               1  \n",
       "55474       0               0       1               1  \n",
       "57988       0               0       1               0  \n",
       "47645       0               0       1               0  \n",
       "63175       1               0       1               0  \n",
       "38531       0               0       0               1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio_complete_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d3c9856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     47209\n",
       "yes    21088\n",
       "Name: obesity_status, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio_complete_df[\"obesity_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd259e2",
   "metadata": {},
   "source": [
    "## Pre processing data for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5ed01bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight_status</th>\n",
       "      <th>obesity_status</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>smoker</th>\n",
       "      <th>alcohol_intake</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  gender  weight   BMI  weight_status  obesity_status  systolic_bp  \\\n",
       "0   51       1    29.0   9.9              1               0        110.0   \n",
       "1   49       1    30.0  11.7              1               0        120.0   \n",
       "2   58       1    30.0  14.7              1               0        103.0   \n",
       "3   47       2    31.0  10.7              1               0        150.0   \n",
       "4   42       1    32.0  15.0              1               0        100.0   \n",
       "\n",
       "   diastolic_bp  cholesterol  glucose  smoker  alcohol_intake  active  \\\n",
       "0          70.0            2        1       0               0       1   \n",
       "1          80.0            1        1       0               0       1   \n",
       "2          61.0            2        1       0               0       1   \n",
       "3          90.0            2        2       0               0       1   \n",
       "4          70.0            1        1       0               0       0   \n",
       "\n",
       "   cardio_disease  \n",
       "0               1  \n",
       "1               1  \n",
       "2               0  \n",
       "3               1  \n",
       "4               0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID , height columns.\n",
    "cardio_processed_df = cardio_complete_df.drop([\"id\",\"height\"], axis =1)\n",
    "cardio_processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d9b3658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51222, 13)\n",
      "(17075, 13)\n",
      "(51222,)\n",
      "(17075,)\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = cardio_processed_df.drop([\"cardio_disease\"],1).values\n",
    "y = cardio_processed_df[\"cardio_disease\"].values\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 78)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca8ea7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1eb238ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 500)               7000      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 192,501\n",
      "Trainable params: 192,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  500\n",
    "hidden_nodes_layer2 = 300\n",
    "hidden_nodes_layer3 = 100\n",
    "hidden_nodes_layer4 = 50\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27a416e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c4a85539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1601/1601 [==============================] - 3s 1ms/step - loss: 0.5561 - accuracy: 0.7265\n",
      "Epoch 2/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5491 - accuracy: 0.7325\n",
      "Epoch 3/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5470 - accuracy: 0.7319\n",
      "Epoch 4/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5458 - accuracy: 0.7333\n",
      "Epoch 5/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5443 - accuracy: 0.7347\n",
      "Epoch 6/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7346\n",
      "Epoch 7/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5424 - accuracy: 0.7361\n",
      "Epoch 8/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5418 - accuracy: 0.7358\n",
      "Epoch 9/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5413 - accuracy: 0.7362\n",
      "Epoch 10/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5400 - accuracy: 0.7377\n",
      "Epoch 11/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5398 - accuracy: 0.7375\n",
      "Epoch 12/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5390 - accuracy: 0.7390\n",
      "Epoch 13/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5379 - accuracy: 0.7407\n",
      "Epoch 14/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7394\n",
      "Epoch 15/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5360 - accuracy: 0.7411\n",
      "Epoch 16/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5356 - accuracy: 0.7400\n",
      "Epoch 17/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5343 - accuracy: 0.7424\n",
      "Epoch 18/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5328 - accuracy: 0.7429\n",
      "Epoch 19/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5325 - accuracy: 0.7422\n",
      "Epoch 20/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5304 - accuracy: 0.7450\n",
      "Epoch 21/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5294 - accuracy: 0.7456\n",
      "Epoch 22/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5273 - accuracy: 0.7451\n",
      "Epoch 23/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5264 - accuracy: 0.7461\n",
      "Epoch 24/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5254 - accuracy: 0.7457\n",
      "Epoch 25/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5234 - accuracy: 0.7480\n",
      "Epoch 26/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5215 - accuracy: 0.7491\n",
      "Epoch 27/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5195 - accuracy: 0.7513\n",
      "Epoch 28/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5181 - accuracy: 0.7509\n",
      "Epoch 29/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5166 - accuracy: 0.7517\n",
      "Epoch 30/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5138 - accuracy: 0.7525\n",
      "Epoch 31/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5127 - accuracy: 0.7536\n",
      "Epoch 32/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5103 - accuracy: 0.7535\n",
      "Epoch 33/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5081 - accuracy: 0.7559\n",
      "Epoch 34/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5063 - accuracy: 0.7578\n",
      "Epoch 35/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5042 - accuracy: 0.7580\n",
      "Epoch 36/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5016 - accuracy: 0.7599\n",
      "Epoch 37/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4996 - accuracy: 0.7608\n",
      "Epoch 38/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4975 - accuracy: 0.7616\n",
      "Epoch 39/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4958 - accuracy: 0.7638\n",
      "Epoch 40/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4940 - accuracy: 0.7649\n",
      "Epoch 41/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4925 - accuracy: 0.7631\n",
      "Epoch 42/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4892 - accuracy: 0.7661\n",
      "Epoch 43/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4869 - accuracy: 0.7672\n",
      "Epoch 44/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4857 - accuracy: 0.7671\n",
      "Epoch 45/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4838 - accuracy: 0.7691\n",
      "Epoch 46/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4819 - accuracy: 0.7708\n",
      "Epoch 47/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4790 - accuracy: 0.7720\n",
      "Epoch 48/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4771 - accuracy: 0.7724\n",
      "Epoch 49/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4764 - accuracy: 0.7728\n",
      "Epoch 50/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4724 - accuracy: 0.7742\n",
      "Epoch 51/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4711 - accuracy: 0.7753\n",
      "Epoch 52/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4710 - accuracy: 0.7759\n",
      "Epoch 53/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4685 - accuracy: 0.7766\n",
      "Epoch 54/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4661 - accuracy: 0.7780\n",
      "Epoch 55/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4652 - accuracy: 0.7778\n",
      "Epoch 56/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4629 - accuracy: 0.7793\n",
      "Epoch 57/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4615 - accuracy: 0.7798\n",
      "Epoch 58/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4589 - accuracy: 0.7811\n",
      "Epoch 59/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4576 - accuracy: 0.7821\n",
      "Epoch 60/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4579 - accuracy: 0.7819\n",
      "Epoch 61/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4520 - accuracy: 0.7851\n",
      "Epoch 62/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4565 - accuracy: 0.7831\n",
      "Epoch 63/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4528 - accuracy: 0.7848\n",
      "Epoch 64/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4500 - accuracy: 0.7855\n",
      "Epoch 65/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4499 - accuracy: 0.7860\n",
      "Epoch 66/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4464 - accuracy: 0.7879\n",
      "Epoch 67/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4460 - accuracy: 0.7871\n",
      "Epoch 68/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4458 - accuracy: 0.7877\n",
      "Epoch 69/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4417 - accuracy: 0.7900\n",
      "Epoch 70/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4426 - accuracy: 0.7902\n",
      "Epoch 71/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4394 - accuracy: 0.7909\n",
      "Epoch 72/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4361 - accuracy: 0.7915\n",
      "Epoch 73/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4374 - accuracy: 0.7907\n",
      "Epoch 74/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4351 - accuracy: 0.7926\n",
      "Epoch 75/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4328 - accuracy: 0.7940\n",
      "Epoch 76/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4328 - accuracy: 0.7939\n",
      "Epoch 77/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4352 - accuracy: 0.7941\n",
      "Epoch 78/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4277 - accuracy: 0.7959\n",
      "Epoch 79/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4273 - accuracy: 0.7975\n",
      "Epoch 80/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4273 - accuracy: 0.7965\n",
      "Epoch 81/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4304 - accuracy: 0.7954\n",
      "Epoch 82/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4241 - accuracy: 0.7981\n",
      "Epoch 83/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4233 - accuracy: 0.7986\n",
      "Epoch 84/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4240 - accuracy: 0.7992\n",
      "Epoch 85/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4196 - accuracy: 0.8011\n",
      "Epoch 86/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4194 - accuracy: 0.8013\n",
      "Epoch 87/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4196 - accuracy: 0.8008\n",
      "Epoch 88/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4179 - accuracy: 0.8015\n",
      "Epoch 89/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4171 - accuracy: 0.8017\n",
      "Epoch 90/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4166 - accuracy: 0.8027\n",
      "Epoch 91/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4180 - accuracy: 0.8031\n",
      "Epoch 92/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4131 - accuracy: 0.8042\n",
      "Epoch 93/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4149 - accuracy: 0.8044\n",
      "Epoch 94/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4109 - accuracy: 0.8049\n",
      "Epoch 95/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4103 - accuracy: 0.8048\n",
      "Epoch 96/100\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4075 - accuracy: 0.8066\n",
      "Epoch 97/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4078 - accuracy: 0.8070\n",
      "Epoch 98/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4062 - accuracy: 0.8066\n",
      "Epoch 99/100\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4070 - accuracy: 0.8084\n",
      "Epoch 100/100\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4020 - accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "46d4c261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "333c22c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fdb20a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 - 0s - loss: 1.1123 - accuracy: 0.7064\n",
      "Loss: 1.112, Accuracy: 0.706\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {(model_loss):.3f}, Accuracy: {(model_accuracy):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e05e7",
   "metadata": {},
   "source": [
    "## \"The accuracy of this model is 71.0% after adding additional neurons to each of the 4 hidden layers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87905049",
   "metadata": {},
   "source": [
    "## Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3336301b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 500)               7000      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 192,501\n",
      "Trainable params: 192,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 500\n",
    "hidden_nodes_layer2 = 300\n",
    "hidden_nodes_layer3 = 100\n",
    "hidden_nodes_layer4 = 50\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf6a9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb5f876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5559 - accuracy: 0.7284\n",
      "Epoch 2/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7303\n",
      "Epoch 3/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5472 - accuracy: 0.7330\n",
      "Epoch 4/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5455 - accuracy: 0.7333\n",
      "Epoch 5/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7352\n",
      "Epoch 6/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5437 - accuracy: 0.7347\n",
      "Epoch 7/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5428 - accuracy: 0.7349\n",
      "Epoch 8/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5419 - accuracy: 0.7354\n",
      "Epoch 9/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5413 - accuracy: 0.7364\n",
      "Epoch 10/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5410 - accuracy: 0.7372\n",
      "Epoch 11/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5398 - accuracy: 0.7388\n",
      "Epoch 12/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5392 - accuracy: 0.7379\n",
      "Epoch 13/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5383 - accuracy: 0.7388\n",
      "Epoch 14/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5378 - accuracy: 0.7393\n",
      "Epoch 15/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5369 - accuracy: 0.7403\n",
      "Epoch 16/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5359 - accuracy: 0.7399\n",
      "Epoch 17/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5352 - accuracy: 0.7413\n",
      "Epoch 18/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5338 - accuracy: 0.7417\n",
      "Epoch 19/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5329 - accuracy: 0.7419\n",
      "Epoch 20/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5311 - accuracy: 0.7432\n",
      "Epoch 21/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5304 - accuracy: 0.7433\n",
      "Epoch 22/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5286 - accuracy: 0.7443\n",
      "Epoch 23/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5266 - accuracy: 0.7458\n",
      "Epoch 24/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5254 - accuracy: 0.7465\n",
      "Epoch 25/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5231 - accuracy: 0.7480\n",
      "Epoch 26/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5221 - accuracy: 0.7485\n",
      "Epoch 27/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5201 - accuracy: 0.7498\n",
      "Epoch 28/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5175 - accuracy: 0.7508\n",
      "Epoch 29/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5156 - accuracy: 0.7512\n",
      "Epoch 30/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5142 - accuracy: 0.7521\n",
      "Epoch 31/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.5123 - accuracy: 0.7535\n",
      "Epoch 32/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5097 - accuracy: 0.7552\n",
      "Epoch 33/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5077 - accuracy: 0.7559\n",
      "Epoch 34/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.5060 - accuracy: 0.7567\n",
      "Epoch 35/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.5038 - accuracy: 0.7589\n",
      "Epoch 36/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.5016 - accuracy: 0.7593\n",
      "Epoch 37/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4990 - accuracy: 0.7611\n",
      "Epoch 38/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4976 - accuracy: 0.7618\n",
      "Epoch 39/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4951 - accuracy: 0.7622\n",
      "Epoch 40/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4946 - accuracy: 0.7629\n",
      "Epoch 41/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4922 - accuracy: 0.7640\n",
      "Epoch 42/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4885 - accuracy: 0.7663\n",
      "Epoch 43/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4878 - accuracy: 0.7674\n",
      "Epoch 44/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4848 - accuracy: 0.7698\n",
      "Epoch 45/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4826 - accuracy: 0.7699\n",
      "Epoch 46/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4812 - accuracy: 0.7702\n",
      "Epoch 47/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4784 - accuracy: 0.7704\n",
      "Epoch 48/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4776 - accuracy: 0.7710\n",
      "Epoch 49/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4749 - accuracy: 0.7728\n",
      "Epoch 50/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4725 - accuracy: 0.7742\n",
      "Epoch 51/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4723 - accuracy: 0.7743\n",
      "Epoch 52/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4702 - accuracy: 0.7760\n",
      "Epoch 53/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4683 - accuracy: 0.7771\n",
      "Epoch 54/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4669 - accuracy: 0.7768\n",
      "Epoch 55/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4637 - accuracy: 0.7797\n",
      "Epoch 56/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4631 - accuracy: 0.7798\n",
      "Epoch 57/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4586 - accuracy: 0.7805\n",
      "Epoch 58/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4582 - accuracy: 0.7818\n",
      "Epoch 59/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4579 - accuracy: 0.7826\n",
      "Epoch 60/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4542 - accuracy: 0.7840\n",
      "Epoch 61/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4540 - accuracy: 0.7843\n",
      "Epoch 62/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4526 - accuracy: 0.7838\n",
      "Epoch 63/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4515 - accuracy: 0.7848\n",
      "Epoch 64/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4478 - accuracy: 0.7865\n",
      "Epoch 65/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4463 - accuracy: 0.7872\n",
      "Epoch 66/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4481 - accuracy: 0.7869\n",
      "Epoch 67/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4453 - accuracy: 0.7879\n",
      "Epoch 68/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4433 - accuracy: 0.7883\n",
      "Epoch 69/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4404 - accuracy: 0.7899\n",
      "Epoch 70/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4398 - accuracy: 0.7898\n",
      "Epoch 71/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4376 - accuracy: 0.7915\n",
      "Epoch 72/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4378 - accuracy: 0.7917\n",
      "Epoch 73/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4360 - accuracy: 0.7923\n",
      "Epoch 74/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4336 - accuracy: 0.7934\n",
      "Epoch 75/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4332 - accuracy: 0.7930\n",
      "Epoch 76/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4313 - accuracy: 0.7945\n",
      "Epoch 77/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4302 - accuracy: 0.7948\n",
      "Epoch 78/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4287 - accuracy: 0.7955\n",
      "Epoch 79/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4269 - accuracy: 0.7970\n",
      "Epoch 80/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4232 - accuracy: 0.7983\n",
      "Epoch 81/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4265 - accuracy: 0.7965\n",
      "Epoch 82/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4253 - accuracy: 0.7978\n",
      "Epoch 83/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4206 - accuracy: 0.7997\n",
      "Epoch 84/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4207 - accuracy: 0.7997\n",
      "Epoch 85/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4173 - accuracy: 0.8016\n",
      "Epoch 86/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4178 - accuracy: 0.8012\n",
      "Epoch 87/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4168 - accuracy: 0.8024\n",
      "Epoch 88/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.4166 - accuracy: 0.8023\n",
      "Epoch 89/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4156 - accuracy: 0.8024\n",
      "Epoch 90/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4129 - accuracy: 0.8034\n",
      "Epoch 91/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4095 - accuracy: 0.8060\n",
      "Epoch 92/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4120 - accuracy: 0.8041\n",
      "Epoch 93/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4109 - accuracy: 0.8048\n",
      "Epoch 94/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4079 - accuracy: 0.8070\n",
      "Epoch 95/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4125 - accuracy: 0.8052\n",
      "Epoch 96/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4082 - accuracy: 0.8073\n",
      "Epoch 97/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4084 - accuracy: 0.8077\n",
      "Epoch 98/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4041 - accuracy: 0.8084\n",
      "Epoch 99/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4047 - accuracy: 0.8074\n",
      "Epoch 100/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4011 - accuracy: 0.8084\n",
      "Epoch 101/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4034 - accuracy: 0.8081\n",
      "Epoch 102/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.4015 - accuracy: 0.8095\n",
      "Epoch 103/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.4010 - accuracy: 0.8099\n",
      "Epoch 104/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3968 - accuracy: 0.8120\n",
      "Epoch 105/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3958 - accuracy: 0.8114\n",
      "Epoch 106/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3970 - accuracy: 0.8122\n",
      "Epoch 107/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3984 - accuracy: 0.8115\n",
      "Epoch 108/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3947 - accuracy: 0.8132\n",
      "Epoch 109/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3926 - accuracy: 0.8145\n",
      "Epoch 110/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3903 - accuracy: 0.8143\n",
      "Epoch 111/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3914 - accuracy: 0.8136\n",
      "Epoch 112/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3934 - accuracy: 0.8145\n",
      "Epoch 113/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3859 - accuracy: 0.8157\n",
      "Epoch 114/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3897 - accuracy: 0.8157\n",
      "Epoch 115/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3887 - accuracy: 0.8157\n",
      "Epoch 116/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3845 - accuracy: 0.8173\n",
      "Epoch 117/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3869 - accuracy: 0.8158\n",
      "Epoch 118/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3875 - accuracy: 0.8158\n",
      "Epoch 119/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3807 - accuracy: 0.8189\n",
      "Epoch 120/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3850 - accuracy: 0.8171\n",
      "Epoch 121/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3805 - accuracy: 0.8198\n",
      "Epoch 122/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3809 - accuracy: 0.8186\n",
      "Epoch 123/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3838 - accuracy: 0.8186\n",
      "Epoch 124/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3826 - accuracy: 0.8191\n",
      "Epoch 125/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3769 - accuracy: 0.8197\n",
      "Epoch 126/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3780 - accuracy: 0.8218\n",
      "Epoch 127/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3792 - accuracy: 0.8197\n",
      "Epoch 128/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3754 - accuracy: 0.8225\n",
      "Epoch 129/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3729 - accuracy: 0.8225\n",
      "Epoch 130/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3784 - accuracy: 0.8213\n",
      "Epoch 131/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3714 - accuracy: 0.8238\n",
      "Epoch 132/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3748 - accuracy: 0.8224\n",
      "Epoch 133/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3754 - accuracy: 0.8230\n",
      "Epoch 134/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3699 - accuracy: 0.8245\n",
      "Epoch 135/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3702 - accuracy: 0.8241\n",
      "Epoch 136/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3697 - accuracy: 0.8255\n",
      "Epoch 137/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3704 - accuracy: 0.8251\n",
      "Epoch 138/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3670 - accuracy: 0.8266\n",
      "Epoch 139/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3684 - accuracy: 0.8253\n",
      "Epoch 140/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3659 - accuracy: 0.8265\n",
      "Epoch 141/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3676 - accuracy: 0.8267\n",
      "Epoch 142/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3626 - accuracy: 0.8286\n",
      "Epoch 143/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3677 - accuracy: 0.8273\n",
      "Epoch 144/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3642 - accuracy: 0.8285\n",
      "Epoch 145/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3623 - accuracy: 0.8286\n",
      "Epoch 146/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3628 - accuracy: 0.8284\n",
      "Epoch 147/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3632 - accuracy: 0.8287\n",
      "Epoch 148/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3618 - accuracy: 0.8287\n",
      "Epoch 149/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3623 - accuracy: 0.8281\n",
      "Epoch 150/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3575 - accuracy: 0.8316\n",
      "Epoch 151/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3591 - accuracy: 0.8299\n",
      "Epoch 152/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3574 - accuracy: 0.8315\n",
      "Epoch 153/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3590 - accuracy: 0.8311\n",
      "Epoch 154/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3619 - accuracy: 0.8293\n",
      "Epoch 155/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3572 - accuracy: 0.8311\n",
      "Epoch 156/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3508 - accuracy: 0.8336\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3566 - accuracy: 0.8330\n",
      "Epoch 158/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3504 - accuracy: 0.8332\n",
      "Epoch 159/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3564 - accuracy: 0.8331\n",
      "Epoch 160/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3532 - accuracy: 0.8329\n",
      "Epoch 161/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3605 - accuracy: 0.8319\n",
      "Epoch 162/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3508 - accuracy: 0.8343\n",
      "Epoch 163/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3525 - accuracy: 0.8343\n",
      "Epoch 164/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3535 - accuracy: 0.8351\n",
      "Epoch 165/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3509 - accuracy: 0.8353\n",
      "Epoch 166/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3499 - accuracy: 0.8339\n",
      "Epoch 167/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3495 - accuracy: 0.8361\n",
      "Epoch 168/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3475 - accuracy: 0.8360\n",
      "Epoch 169/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3475 - accuracy: 0.8357\n",
      "Epoch 170/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3474 - accuracy: 0.8363\n",
      "Epoch 171/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3452 - accuracy: 0.8370\n",
      "Epoch 172/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3494 - accuracy: 0.8352\n",
      "Epoch 173/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3452 - accuracy: 0.8376\n",
      "Epoch 174/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3415 - accuracy: 0.8393\n",
      "Epoch 175/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3477 - accuracy: 0.8363\n",
      "Epoch 176/200\n",
      "1601/1601 [==============================] - 3s 2ms/step - loss: 0.3445 - accuracy: 0.8384\n",
      "Epoch 177/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3441 - accuracy: 0.8392\n",
      "Epoch 178/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3430 - accuracy: 0.8382\n",
      "Epoch 179/200\n",
      "1601/1601 [==============================] - 2s 2ms/step - loss: 0.3434 - accuracy: 0.8383\n",
      "Epoch 180/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3426 - accuracy: 0.8392\n",
      "Epoch 181/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3421 - accuracy: 0.8386\n",
      "Epoch 182/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3384 - accuracy: 0.8408\n",
      "Epoch 183/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3398 - accuracy: 0.8403\n",
      "Epoch 184/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3405 - accuracy: 0.8404\n",
      "Epoch 185/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3449 - accuracy: 0.8392\n",
      "Epoch 186/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3397 - accuracy: 0.8411\n",
      "Epoch 187/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3383 - accuracy: 0.8413\n",
      "Epoch 188/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3353 - accuracy: 0.8409\n",
      "Epoch 189/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3393 - accuracy: 0.8401\n",
      "Epoch 190/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3389 - accuracy: 0.8410\n",
      "Epoch 191/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3356 - accuracy: 0.8423\n",
      "Epoch 192/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3337 - accuracy: 0.8436\n",
      "Epoch 193/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3350 - accuracy: 0.8434\n",
      "Epoch 194/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3345 - accuracy: 0.8418\n",
      "Epoch 195/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3338 - accuracy: 0.8438\n",
      "Epoch 196/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3312 - accuracy: 0.8448\n",
      "Epoch 197/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3309 - accuracy: 0.8439\n",
      "Epoch 198/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3315 - accuracy: 0.8429\n",
      "Epoch 199/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3367 - accuracy: 0.8410\n",
      "Epoch 200/200\n",
      "1601/1601 [==============================] - 2s 1ms/step - loss: 0.3294 - accuracy: 0.8443\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c83f828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 - 0s - loss: 1.6407 - accuracy: 0.6959\n",
      "Loss: 1.641, Accuracy: 0.696\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {(model_loss):.3f}, Accuracy: {(model_accuracy):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e828eb",
   "metadata": {},
   "source": [
    "## The accuracy is 70% after adding additional neurons to the 4 hidden layers and epoch of 200. This looks like a classic case of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5038b6",
   "metadata": {},
   "source": [
    "### Trial 3 with 5 hidden layers and optimizer as \"rmsprop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ad486ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 700)               9800      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 490,801\n",
      "Trainable params: 490,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 700\n",
    "hidden_nodes_layer2 = 500\n",
    "hidden_nodes_layer3 = 200\n",
    "hidden_nodes_layer4 = 100\n",
    "hidden_nodes_layer5 = 50\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09664e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer =\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0cec15bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5603 - accuracy: 0.7258\n",
      "Epoch 2/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5528 - accuracy: 0.7307\n",
      "Epoch 3/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5507 - accuracy: 0.7317\n",
      "Epoch 4/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5487 - accuracy: 0.7336\n",
      "Epoch 5/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5482 - accuracy: 0.7331\n",
      "Epoch 6/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5469 - accuracy: 0.7340\n",
      "Epoch 7/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5462 - accuracy: 0.7355\n",
      "Epoch 8/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5464 - accuracy: 0.7349\n",
      "Epoch 9/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5460 - accuracy: 0.7352\n",
      "Epoch 10/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5473 - accuracy: 0.7355\n",
      "Epoch 11/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5465 - accuracy: 0.7365\n",
      "Epoch 12/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5470 - accuracy: 0.7353\n",
      "Epoch 13/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5459 - accuracy: 0.7354\n",
      "Epoch 14/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5466 - accuracy: 0.7353\n",
      "Epoch 15/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5479 - accuracy: 0.7359\n",
      "Epoch 16/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5472 - accuracy: 0.7352\n",
      "Epoch 17/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5481 - accuracy: 0.7342\n",
      "Epoch 18/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5475 - accuracy: 0.7356\n",
      "Epoch 19/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5481 - accuracy: 0.7348\n",
      "Epoch 20/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5482 - accuracy: 0.7354\n",
      "Epoch 21/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5493 - accuracy: 0.7349\n",
      "Epoch 22/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5488 - accuracy: 0.7339\n",
      "Epoch 23/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5485 - accuracy: 0.7329\n",
      "Epoch 24/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5479 - accuracy: 0.7343\n",
      "Epoch 25/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5487 - accuracy: 0.7353\n",
      "Epoch 26/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5484 - accuracy: 0.7345\n",
      "Epoch 27/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5507 - accuracy: 0.7348\n",
      "Epoch 28/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5482 - accuracy: 0.7353\n",
      "Epoch 29/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5504 - accuracy: 0.7334\n",
      "Epoch 30/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5505 - accuracy: 0.7355\n",
      "Epoch 31/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5500 - accuracy: 0.7355\n",
      "Epoch 32/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5500 - accuracy: 0.7353\n",
      "Epoch 33/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5540 - accuracy: 0.7335\n",
      "Epoch 34/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5513 - accuracy: 0.7345\n",
      "Epoch 35/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5522 - accuracy: 0.7353\n",
      "Epoch 36/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5509 - accuracy: 0.7348\n",
      "Epoch 37/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5532 - accuracy: 0.7356\n",
      "Epoch 38/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5566 - accuracy: 0.7356\n",
      "Epoch 39/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5508 - accuracy: 0.7360\n",
      "Epoch 40/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5546 - accuracy: 0.7362\n",
      "Epoch 41/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5516 - accuracy: 0.7347\n",
      "Epoch 42/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5554 - accuracy: 0.7347\n",
      "Epoch 43/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5529 - accuracy: 0.7361\n",
      "Epoch 44/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5520 - accuracy: 0.7372\n",
      "Epoch 45/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5531 - accuracy: 0.7368\n",
      "Epoch 46/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5532 - accuracy: 0.7368\n",
      "Epoch 47/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5523 - accuracy: 0.7367\n",
      "Epoch 48/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5512 - accuracy: 0.7379\n",
      "Epoch 49/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5501 - accuracy: 0.7377\n",
      "Epoch 50/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5513 - accuracy: 0.7361\n",
      "Epoch 51/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5514 - accuracy: 0.7363\n",
      "Epoch 52/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5477 - accuracy: 0.7374\n",
      "Epoch 53/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5510 - accuracy: 0.7382\n",
      "Epoch 54/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5495 - accuracy: 0.7385\n",
      "Epoch 55/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5497 - accuracy: 0.7366\n",
      "Epoch 56/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5499 - accuracy: 0.7390\n",
      "Epoch 57/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5492 - accuracy: 0.7394\n",
      "Epoch 58/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5482 - accuracy: 0.7375\n",
      "Epoch 59/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5520 - accuracy: 0.7380\n",
      "Epoch 60/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5531 - accuracy: 0.7384\n",
      "Epoch 61/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5504 - accuracy: 0.7385\n",
      "Epoch 62/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5498 - accuracy: 0.7388\n",
      "Epoch 63/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5502 - accuracy: 0.7385\n",
      "Epoch 64/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5501 - accuracy: 0.7378\n",
      "Epoch 65/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5509 - accuracy: 0.7379\n",
      "Epoch 66/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5491 - accuracy: 0.7387\n",
      "Epoch 67/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5491 - accuracy: 0.7401\n",
      "Epoch 68/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5469 - accuracy: 0.7391\n",
      "Epoch 69/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5499 - accuracy: 0.7392\n",
      "Epoch 70/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5511 - accuracy: 0.7381\n",
      "Epoch 71/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5481 - accuracy: 0.7382\n",
      "Epoch 72/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5485 - accuracy: 0.7398\n",
      "Epoch 73/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5494 - accuracy: 0.7399\n",
      "Epoch 74/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5539 - accuracy: 0.7395\n",
      "Epoch 75/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5491 - accuracy: 0.7401\n",
      "Epoch 76/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5526 - accuracy: 0.7405\n",
      "Epoch 77/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5478 - accuracy: 0.7402\n",
      "Epoch 78/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5505 - accuracy: 0.7412\n",
      "Epoch 79/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5485 - accuracy: 0.7394\n",
      "Epoch 80/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5493 - accuracy: 0.7395\n",
      "Epoch 81/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5542 - accuracy: 0.7391\n",
      "Epoch 82/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5494 - accuracy: 0.7395\n",
      "Epoch 83/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5461 - accuracy: 0.7394\n",
      "Epoch 84/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5567 - accuracy: 0.7396\n",
      "Epoch 85/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5519 - accuracy: 0.7396\n",
      "Epoch 86/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5497 - accuracy: 0.7405\n",
      "Epoch 87/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5544 - accuracy: 0.7406\n",
      "Epoch 88/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5483 - accuracy: 0.7414\n",
      "Epoch 89/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5513 - accuracy: 0.7410\n",
      "Epoch 90/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5518 - accuracy: 0.7425\n",
      "Epoch 91/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5454 - accuracy: 0.7419\n",
      "Epoch 92/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5498 - accuracy: 0.7419\n",
      "Epoch 93/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5536 - accuracy: 0.7411\n",
      "Epoch 94/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5491 - accuracy: 0.7424\n",
      "Epoch 95/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5487 - accuracy: 0.7414\n",
      "Epoch 96/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5485 - accuracy: 0.7423\n",
      "Epoch 97/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5477 - accuracy: 0.7416\n",
      "Epoch 98/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5513 - accuracy: 0.7418\n",
      "Epoch 99/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5474 - accuracy: 0.7419\n",
      "Epoch 100/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5469 - accuracy: 0.7425\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c45dd009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 - 0s - loss: 0.5834 - accuracy: 0.7310\n",
      "Loss: 0.583, Accuracy: 0.731\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {(model_loss):.3f}, Accuracy: {(model_accuracy):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc85b27",
   "metadata": {},
   "source": [
    "## \"The accuracy of this model is 73.0% after adding additional neurons to each of the 5 hidden layers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a6795",
   "metadata": {},
   "source": [
    "## Trial 4: Output with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ff2ec78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 700)               9800      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 485,701\n",
      "Trainable params: 485,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 700\n",
    "hidden_nodes_layer2 = 500\n",
    "hidden_nodes_layer3 = 200\n",
    "hidden_nodes_layer4 = 100\n",
    "hidden_nodes_layer5 = 50\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"softmax\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "618a9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer =\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19322e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5609 - accuracy: 0.4919\n",
      "Epoch 2/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5523 - accuracy: 0.4919\n",
      "Epoch 3/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5491 - accuracy: 0.4919\n",
      "Epoch 4/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5485 - accuracy: 0.4919\n",
      "Epoch 5/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5470 - accuracy: 0.4919\n",
      "Epoch 6/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5467 - accuracy: 0.4919\n",
      "Epoch 7/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5456 - accuracy: 0.4919\n",
      "Epoch 8/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5459 - accuracy: 0.4919\n",
      "Epoch 9/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5462 - accuracy: 0.4919\n",
      "Epoch 10/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5454 - accuracy: 0.4919\n",
      "Epoch 11/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5452 - accuracy: 0.4919\n",
      "Epoch 12/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5449 - accuracy: 0.4919\n",
      "Epoch 13/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5448 - accuracy: 0.4919\n",
      "Epoch 14/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5456 - accuracy: 0.4919\n",
      "Epoch 15/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5458 - accuracy: 0.4919\n",
      "Epoch 16/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5454 - accuracy: 0.4919\n",
      "Epoch 17/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5466 - accuracy: 0.4919\n",
      "Epoch 18/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5473 - accuracy: 0.4919\n",
      "Epoch 19/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5463 - accuracy: 0.4919\n",
      "Epoch 20/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5474 - accuracy: 0.4919\n",
      "Epoch 21/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5490 - accuracy: 0.4919\n",
      "Epoch 22/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5464 - accuracy: 0.4919\n",
      "Epoch 23/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5493 - accuracy: 0.4919\n",
      "Epoch 24/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5495 - accuracy: 0.4919\n",
      "Epoch 25/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5483 - accuracy: 0.4919\n",
      "Epoch 26/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5520 - accuracy: 0.4919\n",
      "Epoch 27/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5503 - accuracy: 0.4919\n",
      "Epoch 28/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5553 - accuracy: 0.4919\n",
      "Epoch 29/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5506 - accuracy: 0.4919\n",
      "Epoch 30/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5505 - accuracy: 0.4919\n",
      "Epoch 31/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5513 - accuracy: 0.4919\n",
      "Epoch 32/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5506 - accuracy: 0.4919\n",
      "Epoch 33/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5519 - accuracy: 0.4919\n",
      "Epoch 34/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5508 - accuracy: 0.4919\n",
      "Epoch 35/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5501 - accuracy: 0.4919\n",
      "Epoch 36/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5514 - accuracy: 0.4919\n",
      "Epoch 37/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5487 - accuracy: 0.4919\n",
      "Epoch 38/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5529 - accuracy: 0.4919\n",
      "Epoch 39/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5500 - accuracy: 0.4919\n",
      "Epoch 40/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5484 - accuracy: 0.4919\n",
      "Epoch 41/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5484 - accuracy: 0.4919\n",
      "Epoch 42/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5477 - accuracy: 0.4919\n",
      "Epoch 43/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5490 - accuracy: 0.4919\n",
      "Epoch 44/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5490 - accuracy: 0.4919\n",
      "Epoch 45/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5501 - accuracy: 0.4919\n",
      "Epoch 46/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5501 - accuracy: 0.4919\n",
      "Epoch 47/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5510 - accuracy: 0.4919\n",
      "Epoch 48/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5512 - accuracy: 0.4919\n",
      "Epoch 49/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5506 - accuracy: 0.4919\n",
      "Epoch 50/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5483 - accuracy: 0.4919\n",
      "Epoch 51/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5498 - accuracy: 0.4919\n",
      "Epoch 52/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5493 - accuracy: 0.4919\n",
      "Epoch 53/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5494 - accuracy: 0.4919\n",
      "Epoch 54/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5501 - accuracy: 0.4919\n",
      "Epoch 55/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5479 - accuracy: 0.4919\n",
      "Epoch 56/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5478 - accuracy: 0.4919\n",
      "Epoch 57/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5480 - accuracy: 0.4919\n",
      "Epoch 58/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5488 - accuracy: 0.4919\n",
      "Epoch 59/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5516 - accuracy: 0.4919\n",
      "Epoch 60/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5486 - accuracy: 0.4919\n",
      "Epoch 61/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5472 - accuracy: 0.4919\n",
      "Epoch 62/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5508 - accuracy: 0.4919\n",
      "Epoch 63/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5478 - accuracy: 0.4919\n",
      "Epoch 64/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5482 - accuracy: 0.4919\n",
      "Epoch 65/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5474 - accuracy: 0.4919\n",
      "Epoch 66/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5493 - accuracy: 0.4919\n",
      "Epoch 67/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5484 - accuracy: 0.4919\n",
      "Epoch 68/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5483 - accuracy: 0.4919\n",
      "Epoch 69/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5481 - accuracy: 0.4919\n",
      "Epoch 70/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5517 - accuracy: 0.4919\n",
      "Epoch 71/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5521 - accuracy: 0.4919\n",
      "Epoch 72/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5501 - accuracy: 0.4919\n",
      "Epoch 73/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5480 - accuracy: 0.4919\n",
      "Epoch 74/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5452 - accuracy: 0.4919\n",
      "Epoch 75/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5492 - accuracy: 0.4919\n",
      "Epoch 76/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5475 - accuracy: 0.4919\n",
      "Epoch 77/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5511 - accuracy: 0.4919\n",
      "Epoch 78/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5471 - accuracy: 0.4919\n",
      "Epoch 79/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5506 - accuracy: 0.4919\n",
      "Epoch 80/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5491 - accuracy: 0.4919\n",
      "Epoch 81/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5451 - accuracy: 0.4919\n",
      "Epoch 82/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5467 - accuracy: 0.4919\n",
      "Epoch 83/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5445 - accuracy: 0.4919\n",
      "Epoch 84/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5470 - accuracy: 0.4919\n",
      "Epoch 85/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5544 - accuracy: 0.4919\n",
      "Epoch 86/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5483 - accuracy: 0.4919\n",
      "Epoch 87/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5482 - accuracy: 0.4919\n",
      "Epoch 88/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5502 - accuracy: 0.4919\n",
      "Epoch 89/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5515 - accuracy: 0.4919\n",
      "Epoch 90/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5477 - accuracy: 0.4919\n",
      "Epoch 91/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5524 - accuracy: 0.4919\n",
      "Epoch 92/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5504 - accuracy: 0.4919\n",
      "Epoch 93/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5559 - accuracy: 0.4919\n",
      "Epoch 94/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5673 - accuracy: 0.4919\n",
      "Epoch 95/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5466 - accuracy: 0.4919\n",
      "Epoch 96/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5462 - accuracy: 0.4919\n",
      "Epoch 97/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5495 - accuracy: 0.4919\n",
      "Epoch 98/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5481 - accuracy: 0.4919\n",
      "Epoch 99/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5464 - accuracy: 0.4919\n",
      "Epoch 100/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5492 - accuracy: 0.4919\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec55bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 - 0s - loss: 0.5751 - accuracy: 0.4975\n",
      "Loss: 0.575, Accuracy: 0.497\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {(model_loss):.3f}, Accuracy: {(model_accuracy):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8b1c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "from graphviz import Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e7a63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_viz(nn,title =\"Trial 3 Neural network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e516c",
   "metadata": {},
   "source": [
    "## Activation Sigmoid, output sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b13e2ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 700)               9800      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 485,701\n",
      "Trainable params: 485,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 700\n",
    "hidden_nodes_layer2 = 500\n",
    "hidden_nodes_layer3 = 200\n",
    "hidden_nodes_layer4 = 100\n",
    "hidden_nodes_layer5 = 50\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"sigmoid\")\n",
    ")\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"sigmoid\")\n",
    ")\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"sigmoid\")\n",
    ")\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"sigmoid\")\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ccf7f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer =\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dca13e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1601/1601 [==============================] - 9s 5ms/step - loss: 0.5596 - accuracy: 0.7230\n",
      "Epoch 2/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5505 - accuracy: 0.7308\n",
      "Epoch 3/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5485 - accuracy: 0.7329\n",
      "Epoch 4/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5469 - accuracy: 0.7339\n",
      "Epoch 5/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5467 - accuracy: 0.7340\n",
      "Epoch 6/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5463 - accuracy: 0.7338\n",
      "Epoch 7/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5456 - accuracy: 0.7357\n",
      "Epoch 8/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5451 - accuracy: 0.7348\n",
      "Epoch 9/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5447 - accuracy: 0.7360\n",
      "Epoch 10/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5448 - accuracy: 0.7368\n",
      "Epoch 11/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5456 - accuracy: 0.7362\n",
      "Epoch 12/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5446 - accuracy: 0.7366\n",
      "Epoch 13/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5442 - accuracy: 0.7366\n",
      "Epoch 14/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5442 - accuracy: 0.7374\n",
      "Epoch 15/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5441 - accuracy: 0.7371\n",
      "Epoch 16/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5452 - accuracy: 0.7376\n",
      "Epoch 17/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5453 - accuracy: 0.7378\n",
      "Epoch 18/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5440 - accuracy: 0.7370\n",
      "Epoch 19/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5433 - accuracy: 0.7373\n",
      "Epoch 20/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5430 - accuracy: 0.7370\n",
      "Epoch 21/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5431 - accuracy: 0.7384\n",
      "Epoch 22/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5422 - accuracy: 0.7388\n",
      "Epoch 23/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5422 - accuracy: 0.7389\n",
      "Epoch 24/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5417 - accuracy: 0.7392\n",
      "Epoch 25/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5417 - accuracy: 0.7390\n",
      "Epoch 26/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5423 - accuracy: 0.7395\n",
      "Epoch 27/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5408 - accuracy: 0.7404\n",
      "Epoch 28/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5401 - accuracy: 0.7406\n",
      "Epoch 29/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5406 - accuracy: 0.7402\n",
      "Epoch 30/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5409 - accuracy: 0.7399\n",
      "Epoch 31/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5397 - accuracy: 0.7401\n",
      "Epoch 32/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5392 - accuracy: 0.7409\n",
      "Epoch 33/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5393 - accuracy: 0.7416\n",
      "Epoch 34/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5388 - accuracy: 0.7416\n",
      "Epoch 35/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5380 - accuracy: 0.7429\n",
      "Epoch 36/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5381 - accuracy: 0.7422\n",
      "Epoch 37/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5375 - accuracy: 0.7440\n",
      "Epoch 38/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5369 - accuracy: 0.7430\n",
      "Epoch 39/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5370 - accuracy: 0.7436\n",
      "Epoch 40/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5361 - accuracy: 0.7443\n",
      "Epoch 41/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5359 - accuracy: 0.7454\n",
      "Epoch 42/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5354 - accuracy: 0.7458\n",
      "Epoch 43/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5348 - accuracy: 0.7456\n",
      "Epoch 44/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5350 - accuracy: 0.7458\n",
      "Epoch 45/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5343 - accuracy: 0.7461\n",
      "Epoch 46/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5329 - accuracy: 0.7481\n",
      "Epoch 47/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5321 - accuracy: 0.7483\n",
      "Epoch 48/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5315 - accuracy: 0.7498\n",
      "Epoch 49/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5311 - accuracy: 0.7497\n",
      "Epoch 50/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5297 - accuracy: 0.7512\n",
      "Epoch 51/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5288 - accuracy: 0.7506\n",
      "Epoch 52/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5273 - accuracy: 0.7534\n",
      "Epoch 53/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5277 - accuracy: 0.7526\n",
      "Epoch 54/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5253 - accuracy: 0.7536\n",
      "Epoch 55/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5238 - accuracy: 0.7568\n",
      "Epoch 56/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5236 - accuracy: 0.7561\n",
      "Epoch 57/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5223 - accuracy: 0.7568\n",
      "Epoch 58/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5215 - accuracy: 0.7564\n",
      "Epoch 59/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5202 - accuracy: 0.7589\n",
      "Epoch 60/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5186 - accuracy: 0.7588\n",
      "Epoch 61/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5185 - accuracy: 0.7607\n",
      "Epoch 62/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5173 - accuracy: 0.7611\n",
      "Epoch 63/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5171 - accuracy: 0.7623\n",
      "Epoch 64/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5157 - accuracy: 0.7629\n",
      "Epoch 65/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5153 - accuracy: 0.7615\n",
      "Epoch 66/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5137 - accuracy: 0.7622\n",
      "Epoch 67/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5131 - accuracy: 0.7621\n",
      "Epoch 68/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5122 - accuracy: 0.7651\n",
      "Epoch 69/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5106 - accuracy: 0.7658\n",
      "Epoch 70/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5089 - accuracy: 0.7668\n",
      "Epoch 71/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5082 - accuracy: 0.7665\n",
      "Epoch 72/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5077 - accuracy: 0.7676\n",
      "Epoch 73/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5075 - accuracy: 0.7670\n",
      "Epoch 74/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5067 - accuracy: 0.7682\n",
      "Epoch 75/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5063 - accuracy: 0.7679\n",
      "Epoch 76/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5039 - accuracy: 0.7699\n",
      "Epoch 77/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5036 - accuracy: 0.7705\n",
      "Epoch 78/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5017 - accuracy: 0.7707\n",
      "Epoch 79/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5032 - accuracy: 0.7720\n",
      "Epoch 80/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5016 - accuracy: 0.7716\n",
      "Epoch 81/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5009 - accuracy: 0.7728\n",
      "Epoch 82/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.4998 - accuracy: 0.7732\n",
      "Epoch 83/100\n",
      "1601/1601 [==============================] - 892s 558ms/step - loss: 0.4967 - accuracy: 0.7754\n",
      "Epoch 84/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4965 - accuracy: 0.7741\n",
      "Epoch 85/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4956 - accuracy: 0.7750\n",
      "Epoch 86/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4950 - accuracy: 0.7762\n",
      "Epoch 87/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4938 - accuracy: 0.7767\n",
      "Epoch 88/100\n",
      "1601/1601 [==============================] - 9s 6ms/step - loss: 0.4920 - accuracy: 0.7771\n",
      "Epoch 89/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4923 - accuracy: 0.7783\n",
      "Epoch 90/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4912 - accuracy: 0.7782\n",
      "Epoch 91/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4906 - accuracy: 0.7780\n",
      "Epoch 92/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4897 - accuracy: 0.7794\n",
      "Epoch 93/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4882 - accuracy: 0.7787\n",
      "Epoch 94/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4878 - accuracy: 0.7799\n",
      "Epoch 95/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4864 - accuracy: 0.7803\n",
      "Epoch 96/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4876 - accuracy: 0.7795\n",
      "Epoch 97/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4857 - accuracy: 0.7811\n",
      "Epoch 98/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4851 - accuracy: 0.7818\n",
      "Epoch 99/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4830 - accuracy: 0.7830\n",
      "Epoch 100/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.4835 - accuracy: 0.7824\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "452c79e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 - 1s - loss: 0.6510 - accuracy: 0.7136\n",
      "Loss: 0.651, Accuracy: 0.714\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {(model_loss):.3f}, Accuracy: {(model_accuracy):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009efbf",
   "metadata": {},
   "source": [
    "## The best accuracy is obtained with 5 hidden layers, activation: relu , output:sigmoid and optimizer =\"rmsprop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9396b481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 700)               9800      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 500)               350500    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 485,701\n",
      "Trainable params: 485,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 700\n",
    "hidden_nodes_layer2 = 500\n",
    "hidden_nodes_layer3 = 200\n",
    "hidden_nodes_layer4 = 100\n",
    "hidden_nodes_layer5 = 50\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18851af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer =\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac9e16d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5605 - accuracy: 0.7264\n",
      "Epoch 2/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5526 - accuracy: 0.7308\n",
      "Epoch 3/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5498 - accuracy: 0.7331\n",
      "Epoch 4/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5487 - accuracy: 0.7332\n",
      "Epoch 5/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5476 - accuracy: 0.7341\n",
      "Epoch 6/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5470 - accuracy: 0.7348\n",
      "Epoch 7/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5469 - accuracy: 0.7336\n",
      "Epoch 8/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5464 - accuracy: 0.7350\n",
      "Epoch 9/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5462 - accuracy: 0.7344\n",
      "Epoch 10/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5463 - accuracy: 0.7352\n",
      "Epoch 11/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5460 - accuracy: 0.7354\n",
      "Epoch 12/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5458 - accuracy: 0.7358\n",
      "Epoch 13/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5457 - accuracy: 0.7360\n",
      "Epoch 14/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5462 - accuracy: 0.7362\n",
      "Epoch 15/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5447 - accuracy: 0.7364\n",
      "Epoch 16/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5459 - accuracy: 0.7373\n",
      "Epoch 17/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5454 - accuracy: 0.7373\n",
      "Epoch 18/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5466 - accuracy: 0.7364\n",
      "Epoch 19/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5462 - accuracy: 0.7370\n",
      "Epoch 20/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5473 - accuracy: 0.7372\n",
      "Epoch 21/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5449 - accuracy: 0.7372\n",
      "Epoch 22/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5473 - accuracy: 0.7374\n",
      "Epoch 23/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5469 - accuracy: 0.7369\n",
      "Epoch 24/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5495 - accuracy: 0.7368\n",
      "Epoch 25/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5500 - accuracy: 0.7368\n",
      "Epoch 26/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5489 - accuracy: 0.7359\n",
      "Epoch 27/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5502 - accuracy: 0.7367\n",
      "Epoch 28/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5532 - accuracy: 0.7368\n",
      "Epoch 29/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5528 - accuracy: 0.7362\n",
      "Epoch 30/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5514 - accuracy: 0.7364\n",
      "Epoch 31/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5526 - accuracy: 0.7370\n",
      "Epoch 32/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5499 - accuracy: 0.7380\n",
      "Epoch 33/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5530 - accuracy: 0.7355\n",
      "Epoch 34/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5508 - accuracy: 0.7358\n",
      "Epoch 35/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5548 - accuracy: 0.7380\n",
      "Epoch 36/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5487 - accuracy: 0.7376\n",
      "Epoch 37/100\n",
      "1601/1601 [==============================] - 9s 6ms/step - loss: 0.5491 - accuracy: 0.7366\n",
      "Epoch 38/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5505 - accuracy: 0.7370\n",
      "Epoch 39/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5512 - accuracy: 0.7373\n",
      "Epoch 40/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5496 - accuracy: 0.7379\n",
      "Epoch 41/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5505 - accuracy: 0.7377\n",
      "Epoch 42/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5514 - accuracy: 0.7366\n",
      "Epoch 43/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5488 - accuracy: 0.7380\n",
      "Epoch 44/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5508 - accuracy: 0.7377\n",
      "Epoch 45/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5503 - accuracy: 0.7372\n",
      "Epoch 46/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5515 - accuracy: 0.7381\n",
      "Epoch 47/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5518 - accuracy: 0.7381\n",
      "Epoch 48/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5525 - accuracy: 0.7378\n",
      "Epoch 49/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5530 - accuracy: 0.7369\n",
      "Epoch 50/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5529 - accuracy: 0.7368\n",
      "Epoch 51/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5512 - accuracy: 0.7362\n",
      "Epoch 52/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5493 - accuracy: 0.7376\n",
      "Epoch 53/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5533 - accuracy: 0.7361\n",
      "Epoch 54/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5524 - accuracy: 0.7376\n",
      "Epoch 55/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5539 - accuracy: 0.7383\n",
      "Epoch 56/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5540 - accuracy: 0.7388\n",
      "Epoch 57/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5531 - accuracy: 0.7382\n",
      "Epoch 58/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5519 - accuracy: 0.7389\n",
      "Epoch 59/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5513 - accuracy: 0.7376\n",
      "Epoch 60/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5534 - accuracy: 0.7382\n",
      "Epoch 61/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5514 - accuracy: 0.7386\n",
      "Epoch 62/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5502 - accuracy: 0.7395\n",
      "Epoch 63/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5500 - accuracy: 0.7381\n",
      "Epoch 64/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5485 - accuracy: 0.7391\n",
      "Epoch 65/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5500 - accuracy: 0.7388\n",
      "Epoch 66/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5489 - accuracy: 0.7388\n",
      "Epoch 67/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5488 - accuracy: 0.7391\n",
      "Epoch 68/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5498 - accuracy: 0.7390\n",
      "Epoch 69/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5497 - accuracy: 0.7394\n",
      "Epoch 70/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5493 - accuracy: 0.7403\n",
      "Epoch 71/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5492 - accuracy: 0.7384\n",
      "Epoch 72/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5468 - accuracy: 0.7404\n",
      "Epoch 73/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5558 - accuracy: 0.7403\n",
      "Epoch 74/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5486 - accuracy: 0.7403\n",
      "Epoch 75/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5519 - accuracy: 0.7400\n",
      "Epoch 76/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5497 - accuracy: 0.7393\n",
      "Epoch 77/100\n",
      "1601/1601 [==============================] - 9s 5ms/step - loss: 0.5494 - accuracy: 0.7395\n",
      "Epoch 78/100\n",
      "1601/1601 [==============================] - 9s 5ms/step - loss: 0.5507 - accuracy: 0.7404\n",
      "Epoch 79/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5569 - accuracy: 0.7389\n",
      "Epoch 80/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5499 - accuracy: 0.7394\n",
      "Epoch 81/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5504 - accuracy: 0.7403\n",
      "Epoch 82/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5618 - accuracy: 0.7412\n",
      "Epoch 83/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5541 - accuracy: 0.7408\n",
      "Epoch 84/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5545 - accuracy: 0.7418\n",
      "Epoch 85/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5553 - accuracy: 0.7416\n",
      "Epoch 86/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5528 - accuracy: 0.7418\n",
      "Epoch 87/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5573 - accuracy: 0.7420\n",
      "Epoch 88/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5567 - accuracy: 0.7429\n",
      "Epoch 89/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5562 - accuracy: 0.7433\n",
      "Epoch 90/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5524 - accuracy: 0.7419\n",
      "Epoch 91/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5556 - accuracy: 0.7405\n",
      "Epoch 92/100\n",
      "1601/1601 [==============================] - 7s 5ms/step - loss: 0.5522 - accuracy: 0.7414\n",
      "Epoch 93/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5591 - accuracy: 0.7405\n",
      "Epoch 94/100\n",
      "1601/1601 [==============================] - 7s 4ms/step - loss: 0.5567 - accuracy: 0.7414\n",
      "Epoch 95/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5551 - accuracy: 0.7406\n",
      "Epoch 96/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5595 - accuracy: 0.7428\n",
      "Epoch 97/100\n",
      "1601/1601 [==============================] - 9s 6ms/step - loss: 0.5626 - accuracy: 0.7425\n",
      "Epoch 98/100\n",
      "1601/1601 [==============================] - 9s 6ms/step - loss: 0.5578 - accuracy: 0.7416\n",
      "Epoch 99/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5596 - accuracy: 0.7413\n",
      "Epoch 100/100\n",
      "1601/1601 [==============================] - 8s 5ms/step - loss: 0.5550 - accuracy: 0.7420\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e02438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 - 0s - loss: 0.5967 - accuracy: 0.7309\n",
      "Loss: 0.597, Accuracy: 0.731\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {(model_loss):.3f}, Accuracy: {(model_accuracy):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7a1051d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\",color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27b0b61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\",color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5314b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_viz(nn,title =\"Be Heart Smart Neural Network Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27785470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
